---
type: Study
title: 'Architecture Overview : VLDB 2024'
tags: []
출처: '[clickhouse.com Architecture Overview](https://clickhouse.com/docs/academic_overview)'
---

# Abstract

- 데이터의 양이 늘어나면서, 비즈니스는 과거와 새로운 데이터를 비용 효율적이고 확장 가능한 방법으로 다루면서, 실시간 레이턴시로 많은 양의 동시성 쿼리를 분석할 필요가 생겼다.

- 클릭하우스의 스토리지 레이어는 전통의 log-structured merge 트리와 과거의 데이터에 대한 aggregation, archiving 등의 연속적 변형을 위한 테크닉들이 사용되었다.

- 쿼리는 전통적인 SQL 문법으로 작성되며, 선택적 런타임 코드 컴파일이 갖춰진 SOTA 벡터화 쿼리 실행 엔진으로 처리된다.

- 테이블 함수, 테이블 엔진, 데이터베이스 엔진 레벨에서 다른 DBMS와 통합될 수 있다.

# Introduction

- 클릭하우스는 분석 쿼리에 대한 고성능을 제공하기 위해 디자인된 컬럼 기반 OLAP 데이터베이스

- 모던 분석 데이터 매니지먼트를 관리하기 위한 5개의 키 챌린지를 해결하기 위해 설계됨

    1. 높은 사용률을 가진 거대한 데이터셋

        - 거대한 데이터셋을 다루기 위해 분석DB는 효율적인 인덱싱과 압축 전략을 제공해야 하며, 여러 노드를 데이터를 분포하는 스케일 아웃이 가능해야 한다.

            - 최근 발생한 데이터가 과거의 데이터보다 실시간에 더 많이 연관되므로, 분석 DB는 새로운 데이터를 지속적으로 높은 레이트나 버스트성으로 처리해야 한다.

            - 결과적으로 과거의 데이터의 우선순위를 낮추는 작업을 병렬 리포트 쿼리를 느리게 하지 않고 처리해야 한다.

    2. 동시에 발생하는 쿼리들을 낮은 레이턴시로 처리

        - 쿼리는 일반적으로 애드혹 성으로 카테고리화하거나 반복될 수 있다.

            - 유즈케이스의 상호작용성이 클수록, 낮은 레이턴시를 기대하고, 쿼리 최적화와 실행에서의 챌린지로 이어진다.

            - 반복된 쿼리는 추가적으로 워크로드에 물리젝 DB 레이아웃을 추가할 기회를 준다.

            - 결과적으로 DB는 자주 발생하는 쿼리를 최적하는 기능을 제공해야 한다.

        - 쿼리의 우선순위에 따라 DB는 많은 쿼리가 동시에 발생할때도 CPU, 메모리, 네트워크같은 공유 자원을 우선순위에 따라 접근하도록 할 수 있어야 한다.

    3. 데이터 저장 형태, 저장 위치, 포맷에 대한 다양한 구성

        - 기존의 데이터 아키텍처와 통합하기 위해 현대 분석 DB는 외부 데이터를 어떤 시스템, 위치, 포맷으로부터도 읽어올 수 있는 개방성을 제공해야 한다.

    4. 성능 평가를 지원하는 편리한 쿼리 언어

        - 현실의 OLAP 사용은 추가적인 가벼운 요구사항을 필요한다.

        - 추가적인 프로그래밍 언어 대신 nested 데이터 타입을 갖추고 넓은 regular, aggregation, window function을 갖춘 SQL 문법을 사용하는것을 원한다. 

        - 시스템의 성능이나 개별 쿼리의 성능 측정을 위한 정교한 툴 콜링도 제공해야 한다

    5. Industry-grade의 강건성과 견고한 배포 환경 제공

        - 범용화된 하드웨어의 신뢰도가 낮으므로, 데이터베이스는 노드 failure에 대한 강건함을 위해 데이터 replication을 제공해야 한다.

        - DB는 오래된 랩탑부터 서버까지 어떤 하드웨어에서든 작동할 수 있어야 한다.

        - JVM GC 오버헤드를 피하며 베어메탈 퍼포먼스를 위해 타겟 플랫폼에 대한 네이티브 바이너리로 배포되어야 한다.

- 클릭하우스의 타임라인

    [image](https://app.capacities.io/d1cf29da-a5be-492d-839a-e228b21e0129/c4dbce13-a5a5-4340-9f51-fd6095e695b8)

# Architecture

[image](https://app.capacities.io/d1cf29da-a5be-492d-839a-e228b21e0129/a0eca7e5-ad55-4b7f-a991-4d986408f13c)

- 클릭하우스의 엔진은 3개의 메인 레이어로 나뉘어 있다.

    - 쿼리 처리 레이어

        - 전통적인 패러다임을 따라 입력 쿼리 파싱 -> 논리적 / 물리적 쿼리 플랜 설계 및 최적화 -> 실행 프로세스를 따른다.

        - MonetDB / X100과 유사한 벡터화된 실행 모델과 opportunictic 코드 컴파일을 사용한다.

        - 다양한 기능의 SQL dialect, KQL, PRQL 등을 사용할 수 있다.

    - 스토리지 레이어

        - 테이블 데이터의 포맷과 위치를 캡슐화하는 서로 다른 3개의 카테고리의 테이블 엔진으로 구성되어 있다.

        - 첫번째 카테고리는 머지트리 테이블 엔진으로, ClickHouse의 주 영속성 포맷으로 사용된다.

            - LSM트리의 아이디어를 기반으로 테이블은 수직적으로 정렬된 구조인 데이터 파트로 분리되며, 기본 키 기준으로 정렬되어 백그라운드 프로세스에 의해 병함된다.

            - 개별 머지트리 테이블 엔진은 입력 파트로부터 하나의 행으로 통합한다.

        - 두번째 카테고리는 특수 목적 테이블 엔진으로, 분산 쿼리 실행을 가속에 사용된다.

            - dictionary라고 불리는 인메모리 키밸류 테이블 엔진을 포함한다.

            - 데이터 소스 내/외부에서 주기적으로 실행되는 쿼리의 결과를 캐싱한다.

                - 이를 통해 데이터의 staleness가 허용되는 경우 접근 레이턴시를 크게 감소시킨다.

            - 임시 데이터와 데이터 샤딩 투명성을 위한 분산 테이블 엔진에서 순수한 인메모리 엔진을 포함하여 특수 목적 테이블 엔진이 사용된다.

        - 세번째 카테고리는 관계형 DB나 pub/sub 시스템, 키밸류 시스템 등 외부 시스템과의 양방향성 데이터 교환을 위한 가상 테이블 엔진이다.

            - 가상 엔진은 데이터 레이크와 객체 스토리지와도 상호작용 할 수 있다.

    - 통합 레이어

- 엔진 뒤에 접근 레이어는 유저 세션을 관리하고 어플리케이션과 다양한 프로토콜로 통신한다.

- 쓰레딩, 캐싱, RBAC, 백업, 지속적 모니터링을 위한 orthogonal 컴포넌트가 있다.

- Clickhouse는 의존성 없이 정적 링크 바이너리로 구성된 C++ 프로그램이다.

- 여러개의 노드를 클러스터를 구성하여 샤딩과 레플리케이션을 지원한다.

    - 샤딩은 하나의 테이블을 샤딩 expression에 따라 테이블 샤드로 나눈다.

        - 개별 샤드는 독립적인 테이블이고, 다른 노드에 위치하게 된다.

        - 클라이언트는 샤드를 분리된 테이블로 다루어 직집 읽기/쓰기를 수행할 수 있으며, 모든 테이블 샤드에 대해 글로벌 뷰를 제공하는 분산된 특수 테이블 엔진으로 사용할 수도 있다.

        - 샤딩의 주 목적은 하나의 노드의 처리량을 넘어선 데이터셋을 처리하도록 하는 것.

        - 또다른 목적으로, 복수의 노드로 읽기 / 쓰기 로드를 분산하는 것

            - 추가로, 복수의 노드로 레플리케이션되어 node failure에 대응하도록 하는 것

        - 각 머지 트리 테이블 엔진은 대응되는 ReplicatedMergeTree 엔진으로 모든 샤드가 항상 설정 가능한 수의 레플리카를 가짐을 보장한다.

            - ReplicatedMergeTree 엔진은 Clickhouse Keeper가 제공하는 Raft 컨센서스에 기반한 멀티 마스터 코디네이션을 사용한다.

- 온프레미스, 클라우드, 스탠드얼론, 인프로세스 모드로 작동한다.

    - 온프레스모드에선 유저가 로컬에서 단일 서버 / 샤딩, 레플리케이션을 지원하는 멀티노드 클러스터로 구성한다.

        - 클라이언트는 데이터베이스와 네이티브, MySQL, PostgreSQL의 바이너리 와이어 프로토콜, REST API로 통신한다.

    - 클라우드 모드는 완전 관리형의 오토스케일링 DBaaS인 ClickHouse 클라우드로 제공한다.

    - 스탠드얼론 모드는 파일 분석과 변환을 위한 커맨드라인 유틸리티로 ClickHouse를 사용하여, cat과 grep을 SQL 기반 유닉스 툴로 사용할 수 있도록 한다.

        - config는 필요 없어, 단일 서버 사용으로 제한된다.

    - chDB라고 불리는 인프로세스 모드가 추가되어 Pandas 데이터프레임 사용하는 주피터 노트북을 위한 데이터 분석에 사용된다.

        - DuckDB처럼, chDB는 호스트 프로세스에 높은 성능의 OLAP로 ClickHouse를 임베딩한다.

        - 다른 모드와 비교했을 때 같은 주소 공간에서 작동하기 때문에 DB엔진과 어플리케이션 사이 소스와 결과 전달 프로세스가 효율적이다.

# Storage Layer

- ClickHouse의 네이티브 스토리지 포맷인 MergeTree 테이블 엔진에 대해 다룬다.

## On-Disk Format

- MergeTable* 엔진의 각 테이블은 불변하는 테이블 파트의 집합으로 조직되어 있다.

    - 테이블 파트는 테이블로 row가 삽입되면 생성된다.

- Part는 self-contained 형태이다.

    - 중앙 카탈로그에 대한 추가적인 조회 없이 컨텐츠를 해석할 수 있는 메타데이터를 포함한다.

- 테이블 당 파트의 수를 줄이기 위해, 주기적으로 여러 개의 작은 파트를 더 큰 파트로 병합을 수행한다.

    - 파트는 테이블의 PK 컬럼으로 정렬되기 떄문에, 효율적인 K-merge 정렬이 merge를 위해 사용된다.

    - 작은 파트는 inactive로 마크된 후 결과적으로 읽기가 발생하지 않아 레퍼런스 카운트가 0이 되어 삭제된다. 

- Row는 두 개의 모드로 삽입된다.

    - 동기적 삽입 모드에서, 각 INSERT는 새로운 파트를 만들어 테이블로 추가한다.

        - 병합의 오버헤드를 최소화하기 위해, 클라이언트는 벌크로 튜플을 삽입하도록 한다.

            - 그러나 실시간 분석이 필요하여 클라이언트에서 데이터 배칭을 사용할 수 없는 경우가 있다.

            - 이러한 시나리오에서 비동기적 삽입 모드로 최적화할 수 있다.

    - 비동기적 삽입 모드는 복수의 같은 테이블에 대해 삽입되는 행을 버퍼에 저장한 후, 버퍼 사이즈가 일정 이상으로 커졌을 때 새로운 파트를 생성하도록 한다.

    - MergeTree* 엔진의 병합

        [image](https://app.capacities.io/d1cf29da-a5be-492d-839a-e228b21e0129/f61034a9-4c89-4460-ab7a-dbb4f7994162)

        - 4개의 동기, 2개의 비동기 병합이 발생한 케이스로, 파트가 5개에서 2개로 감소했다.

- LSM Tree와 다양한 DB에서의 구현체와 비교하여, 클릭하우스는 계층 구조로 정리하는 대신 모든 파트를 동일하게 여긴다.

    - 같은 레벨의 파트에서만 병합이 발생하지 않게 된다.

    - 파트의 암시적 시간 순서를 생략하기 때문에, tombstone에 의존하지 않는 업데이트 및 삭제 매커니즘이 필요하다.

    - 다른 LSMTree 기반 DB는 WAL 로깅을 사용하지만, 클릭하우스는 디스크로 작성한다.

- 파트는 디스크의 디렉토리의 대응되어, 하나의 파일이나 각 컬럼을 포함한다.

    - 최적화로서 작은 파트로 구성된 컬럼들은 하나의 파일로 저장되어 공간적 지역성을 증가시킨다.

- 파트의 행은 더 나아가 8192개의 레코드로 분할되어, granule이리고 불린다.

    - granule은 ClickHouse의 스캔과 인덱스 룩업 오퍼레이터가 처리하는 가장 작은 단위의 데이터로 정의된다.

- 온디스크 데이터에 대한 읽기 / 쓰기는 granule 레벨이 아닌 granularity level의 블락으로 수행된다.

    - 컬럼 내에서 여러개의 이웃한 granule을 결합한 레벨에서 수행한다.

    - 새로운 블럭은 설정 가능한 사이즈당 블락으로 설정된다.

        - 블락에 있는 granule의 개수는 변경 가능하고, 컬렁의 데이터 타입과 분포에 의해 결정된다.

    - 블락은 사이즈를 줄이고 I/O 비용을 줄이기 위해 압축된다.

        - LZ4 알고리즘을 기본 압축 알고리즘으로 채택하고 있지만, 유저가 원하는 코덱을 사용할 수 있으며 압축 알고리즘들을 체인으로 구성하여 추가적인 압축도 할 수 있다.

        - 디스크에서 메모리로 로드될때 블락의 압축이 풀린다.

            - 압축된 상황에서 개별 granule에 대한 빠른 랜덤 액세스를 가능하도록 하기 위해, 각 컬럼에 대해 granule id와 압축되지 않은 블락, 압축된 블락의 granule 오프셋을 매핑하여 저장한다.

## Data Pruning

- 대부분의 유즈케이스에서 단일 쿼리 처리를 위해 PB 규모의 데이터를 스캔하는것은 비싸고 느리다.

- 데이터 프루닝을 위한 3가지 방법을 제공한다.

    1. Primary Key Index를 정의할 수 있다.

        - PK 컬럼은 파트 내에서 행의 정렬 순서를 결정할 수 있다.

        - 모든 granule의 첫번째 행의 PK 컬럼 값과 granule id의 매핑을 추가적으로 저장한다.

            - 이 구조로 인메모리에 저장할 수 있는 규모로 구조를 구성할 수 있다.

        - PK의 주 목적은 평등을 평가하고 바이너리 서치를 통해 자주 필터된 컬럼에 대한 범위 예측을 제공하는 것이다.

        - 로컬 정렬은 더 나아가 파트의 병합과 쿼리 최적화를 위해 사용될 수 있다.

            - 정렬 기반 통합이나 PK 컬럼이 정렬 컬럼의 prefix을 형성할 때 물리 실행 계획에서 정렬 오퍼레이터를 제거하는데 사용될 수 있다.

        - EventTime을 Primary Key Index로 설정한하여 페이지 통계를 내는 경우 

            [image](https://app.capacities.io/d1cf29da-a5be-492d-839a-e228b21e0129/035d98ba-b39d-45fb-ba78-6e70c329ac15)

            - 범위 예측에 매치되는 레인지 예측은 프라이머리 키 인덱스를 연속 스캐닝이 아닌 바이너리 서치해서 찾을 수 있다.

    2. Table Projection 생성

        - 다른 프라이머리 키로 정렬된 같을 행을 포함하는 테이블의 다른 버전

        - Projection은 메인 테이블의 프라이머리 키와 다른 열을 필터하는 쿼리의 속도를 향상시킨다.

            - 삽입, 병합, 공간 소비에 대해 오버헤드가 발생한다.

        - 기본적으로 projection은 메인 테이블로 새롭게 삽입된 파트로부터 lazy하게 생성된다.

            - 유저가 가득찬 상태로 프로젝션을 물질화 하지 않는 한 존재하던 파트로는 생성하지 않는다.

        - 쿼리 옵티마이저는 읽기에서 메인 테이블과 프로젝션중 I/O 비용 예측 기반으로 선택한다.

            - 프로젝션이 파트에 존재하지 않으면 fallback으로 메인 테이블의 파트로 수행한다.

    3. skipping indices

        - 프로젝션의 가벼운 형태의 대체제

        - 작은 메타데이터를 여러 연속적인 granule로 저장하여 관계 없은 행을 스캔하지 않도록 한다.

        - 인공적인 인덱스 표현과 granularity 설정 사용을 통해 생성할 수 있다.

        - skipping index type은 다음과 같이 사용할 수 있다.

            - Min-max indices : 각 인덱스 블락의 최대, 최솟값을 저장한다.

            - Set indices : 유니크한 인덱스의 블락 값을 설정 가능한 번호로 저장한다.

                - 작은 local cardinality를 갖는 데이터에서 최적이다.

            - Bloom Filter Indices : 행, 토큰, 설정 가능한 위양성률과 n-gram 값을 사용해 생성한다.

                - 텍스트 서치를 지원하지만, min-max와 set indices과 다르게 range나 부정 예측엔 사용할 수 없다.

## Merge-time Data Transformation

- BI와 관측성의 유즈 케이스는 지속적으로 높은 레이트나 버스트성으로 데이터를 다루어야 한다.

    - 최근 생성한 데이터는 일반적으로 과거 데이터보다 실시간 인사이트에 더 큰 의미를 갖는다.

    - 이러한 유즈케이스는 DB에 데이터 에이징이나 aggregation으로 과거 데이터의 볼륨을 줄이면서 새로운 데이터에 대해 빠른 DB ingestion 속도를 유지하는 것을 필요로 한다.

    - 클릭하우스는 기존에 있던 데이터에 다른 병합 전략으로 지속적인 증가 변환을 지원한다.

        - 테이블이 원하지 않는 값을(outdated되거나 집계되지 않은) 포함함을 보장하지 않는다.

        - 필요시, 모든 병합 시점 변환은 SELECT문에 FINAL 키워드를 명시해 쿼리 시점에 적용할 수 있다.

- Replacing merge

    - 포함하는 파트의 생성 타임스탬프에 기반하여 튜플에 가장 최근에 삽입된 버전만을 유지하고, 다른 버전을 모두 삭제한다.

        - Tuple은 동일한 PK 컬럼값을 가진것과 동등하다고 여긴다.

    - 어떤 튜플을 유지할 것인지 명시하여 특수한 버전 컬럼을 비교용으로 사용할 수도 있다.

    - merge-time 업데이트 메커니즘으로 일반적으로 사용되거나, 삽입 시점 데이터 중복제거의 대안으로 사용된다.

- Aggregating merges

    - 동일한 PK 컬럼 값을 가진 행을 aggregate된 행으로 collapse한다.

        - 프라이머리 키가 아닌 컬럼은 요약하는 값을 갖는 aggregation state의 일부여야 한다.

    - 2개의 부분 통합 state(sum, count for avg())는 새로운 부분 aggregation state로 결합된다.

    - Aggregating merge는 일반 테이블보다 Materialized View에서 자주 사용된다.

        - Materialized view는 소스 테이블에 대해 변환 쿼리를 사용한다.

        - 다른 데이터베이스와 다르게, 클릭하우스는 주기적으로 materialized view를 소스 데이터 전체로 리프레쉬하지 않는다.

            - 소스 테이블로 새로운 파트가 삽입되면 변환 쿼리로 점진적으로 업데이트한다.

        - page impression 수치와 테이블에 정의된 materialized view

            [image](https://app.capacities.io/d1cf29da-a5be-492d-839a-e228b21e0129/f281b2f3-022f-4903-badb-0588886f7949)

            - 소스 테입으로 새 데이터가 삽입되면 변환 쿼리는 리전으로 그룹을 분리하여 최대, 평균 레이턴시를 연산하여 결과를 materialized view로 저장한다.

            - 집계 함수인 avg()와 max() 는 실제 결과 대신 partial aggregation state 반환

                - avg는 sum과 cnt로 저장됨

            - materialize 뷰에 정의된 집계 병합은 지속적으로 다른 파트의 partial aggregation state을 결합한다.

            - 최종 결과를 얻기 위해 유저는 materialized view의 partial aggregation state를 avg와 max로 merge extension과 결합한다.

- TTL merge

    - 과거 데이터에 대한 에이징을 제공한다.

        - deleting, aggregating merge와 다르게 한번에 하나의 파트에 대해서만 수행한다.

    - 트리거와 액션의 맥락으로 정의된다.

        - 트리거는 각 행에 대한 타임스탬프를 연산하는 표현식으로, TTL 병합이 동작하는 시점의 시간과 비교된다.

            - 유저가 행 단위 대해 작업을 수행할 수 있도록 하지만, 모든 row가 주어진 조건을 만족하는지 확인 후 해당 부분 전체에 대한 작업을 실행하는 것이 충분하다고 판단했다.

        - 가능한 액션은 다음과 같다

            - 파트를 다른 볼륨 (더 저렵하고 느린 스토리지)로 이동

            - 압축률이 더 높은 다른 코덱으로 압축

            - 파트 제거

            - 롤업 (집계 함수와 그룹 키로 행을 집계) 

    - 예시

        ```sql
        CREATE TABLE tab ( ts DateTime , msg String )
        ENGINE MergeTree PRIMARY KEY ts
        TTL ( ts + INTERVAL 1 WEEK ) TO VOLUME 's3 '
        ```

        - 클릭하우스는 1주 이상이 된 파트를 s3로 이전한다.

## Updates and Deletes

- MergeTree* 테이블 엔진의 디자인은 append-only 워크로드를 위주로 설계했으나, 데이터를 때때로 수정해야 하는 경우도 존재한다.

    - 데이터 수정과 삭제를 위한 2가지 접근이 존재하고, 둘다 병렬 삽입을 블락하지 않는다.

- Mutation

    - 테이블의 모든 파트를 그 자리에서 다시 작성한다.

    - 테이블이나 컬럼이 임시적으로 두배의 사이즈를 사용하는 것을 막기 위해, atomic하지 않은 동작으로 설계되었다.

        - 병렬적인 SELECT statement는 변한 파트와 변하지 않은 파트 모두 읽을 수 있다.

    - 데이터가 동작이 끝날 때 데이터가 물리적으로 변하는 것을 보장한다.

        - 삭제 뮤테이션은 모든 파트의 데이터를 다시 작성하기 때문에 연산의 코스트가 높다.

- Lightweight delete

    - 내부적인 비트맵 컬럼만 수정하여 삭제 여부를 표기한다.

    - ClickHouse는 SELECT 쿼리에 추가적인 쿼리를 적용하여 삭제된 열을 제외하도록 한다.

    - 특정되지 않은 언젠가 병합되는 시점에 물리적으로 제거된다.

    - 컬럼에 개수에 따라 SELECT가 느려지는 대신 mutation보다 훨씬 빠르게 수행될 수 있다. 

- 동일한 테이블에서 수행된 수정과 삭제 연산은 최대한 적게 발생하도록 하고, 순차적으로 구성하여 논리적 컨플릭트를 피하게 한다.

## Idempotent Inserts

- 클라이언트가 삽입을 위해 서버로 데이터를 전송하고 커넥션 타임아웃이 나는 경우 어떻게 다루어야 하는지 자주 문제가 자주 발생한다.

    - 이 상황에서 클라이언트가 데이터 삽입이 성공했는지 여부를 판단하는 것은 어렵다.

    - 전통적으로는 데이터를 클라이언트가 서버로 다시 전송하고, PK나 unique 제약 조건에 의존하여 중복 삽입을 막도록 하는 것이 일반적이었다.

        - 데이터베이스는 필요한 포인트를 바이너리 트리, radix 트리, 해시 테이블에 기반한 인덱스 구조를 통해 빠르게 접근하여 확인한다.

        - 이러한 데이터 구조는 모든 튜플을 인덱싱하기 때문에, 공간과 수정 오버헤드가 큰 규모의 데이터와 빠른 데이터 처리 속도에 적절하지 않았다.

    - 클릭하우스는 경량화된 대체제를 제공한다.

- 각 insert는 결과적으로 part를 만든다.

    - 서버는 마지막으로 삽입한 N개의 파트의 해시를 유지하고, 알려진 해시를 가진 파트가 재삽입 되었을 때 이를 무시한다.

- 테이블의 레플리케이션의 설정 여부와 관계 없이 테이블의 해시들은 로컬에 Keeper 내부에 각각 저장된다.

    - 결과적으로 insert의 멱등성이 보장되고, 서버가 중복 제거를 관리할 수 잇게 된다.

    - 클라이언트는 타임아웃이 발생했을 때 재전송만 수행하여 문제를 해결할 수 있다.

    - 중복 제거 프로세스에 추가적인 컨트롤로 클라이언트는 part hash로 작동하는 삽입 토큰을 선택적으로 제공할 수 있다.

- 해시 기반 중복 제거가 새로운 행을 해싱하면서 오버헤드가 발생할 수 있지만, 저장과 해시 비교는 무시할 수 있을 정도의 오버헤드가 발생한다.

## Data Replication

- 데이터 레플리케이션은 고가용성을 위한 필수 준비사항이며 (노드 failure에 대응) 로드밸런싱과 제로다운타임 업그레이드에 사용된다.

- 클릭하우스는 replication이 테이블 파트의 집합으로 구성된 테이블 state의 개념과 컬럼명과 타입 등의 테이블 메타데이터에 기반한다.

- 노드는 3개의 연산으로 테이블의 state를 관리한다.

    1. state로 새로운 파트를 삽입한다.

    2. 새로운 파트를 merge로 추가하고, 기존에 존재하던 파트를 state에서 제거한다.

    3. mutation과 DDL로 concrete operation에 기반하여 파트를 추가하거나 제거하고, 테이블 메타데이터를 수정한다.

- 연산은 로컬에서 싱글 노드로 수행되며, global replication log에서 state transition의 연속으로 기록된다.

- replication 로그는 3개의 Raft 합의를 사용하는 Keeper 프로세스 조합으로 관리된다.

    - 이를 통해 분산되며 fault를 저항할 수 있는 코디네이션 노드를 클릭하우스 클러스터에 제공한다.

    - 모든 클러스터 노드는 동일한 replication 로그의 위치를 가리킨다.

- 노드가 로컬 삽입, 병합, mutation, DDL을 수행하면, replication log는 비동기적으로 다른 노드에서 실행된다. 

    - 결과적으로 복제된 테이블은 결과적 일관성(eventual consistency)을 얻게 된다.

    - [Chapter 6: Partitioning](https://app.capacities.io/d1cf29da-a5be-492d-839a-e228b21e0129/26f7de64-4f2d-45f9-9e7f-f672a398a880) 참조

- 앞에 명시된 대부분의 연산은 동기적으로 실행되어 quorom이 새로운 state를 채택하도록 할 수 있다.

- 3개의 클릭하우스 노드에서 최초에 빈 복제 테이블의 예시

    [image](https://app.capacities.io/d1cf29da-a5be-492d-839a-e228b21e0129/19a403c3-67de-4927-800a-d551736882af)

    1. 노드 1번은 최초에 2개의 insert를 받고, replication log를 keeper에 남긴다.

    2. 노드2는 첫번째 로그부터 replay하여 Node 1번의 새로운 파트를 다운로드하고, 노드3은 Part A, B를 replay한다.

    3. 노드3이 두 파트를 병합하고, 입력된 파트를 제거한 후 병합 명령을 replication 로그로 삽입한다.

- 동기화를 최적화하기 위한 3가지 최적화가 존재한다.

    1. 클러스터에 새 노드가 추가되면 처음부터 replication 로그를 리플레이하는 대신, 마지막 replication 로그 엔트리를 작성한 노드의 state를 단순히 복제한다.

    2. 병합는 로컬에서 동일하게 병합하거나, 다른 노드로부터 결과 파트를 fetch하여 처리한다.

        - 정확한 동작은 수정 가능하고, CPU 사용량과 네트워크 IO를 밸런스할 수 있다.

        - 데이터센터간 replication은 로컬 병합으로 operating cost를 감소시킨다.

    3. 노드는 독립적인 replication 로그 엔트리를 병렬적으로 수행한다.

        - 같은 테이블로 새로 삽입된 파트의 fetch, 다른 테이블로의 연산 등을 포함한다.

## ACID Compliance

- 동시성 읽기 / 쓰기 동작의 성능을 최대화하기 위해, latching을 가능한 한 피한다.

- 쿼리를 연관된 모든 테이블의 모든 파트의 스냅샷 안에서 실행한다.

    - 병렬적으로 삽입되거나 병합된 새로운 파트가 포함되지 않도록 보장한다.

- 동시에 수정, 삭제되는 경우를 막기 위해 처리된 파트의 reference count가 쿼리 시간동안 증가한다.

    - 일반적으로, 이는 MVCC의 변형에 해당되는 스냅샷 격리 방식에 해당한다.

    - 결과적으로 스냅샷이 생성될 때 동시 쓰기 작업이 각각 단일 부분에만 영향을 미치는 극히 드문 경우를 제외하고 일반적으로 ACID-compliant를 충족하지 않는다.

- 일반적으로 대부분의 클릭하우스의 쓰기 중심 의사결정은 정전등의 케이스로 새로운 데이터를 잃을 조금의 리스크도 대응할 수 있다.

    - DB는 새로 삽입된 파트를 디스크를 커밋을 force하지 않고, 커널이 배치로 작성하도록 하여 이러한 이점을 얻을 수 있다.

        - 기본 설정이며, forgoping atomicity를 잃는다.

# Query Processing Layer

[image](https://app.capacities.io/d1cf29da-a5be-492d-839a-e228b21e0129/2950f9db-13f1-4d99-b01d-16af806835c5)

- 클릭하우스는 쿼리를 데이터 요소, 데이터 청크,테이블 샤드 레벨에서 병렬화한다.

- 여러 데이터 요소들은 SIMD 지시를 사용하여 한번에 처리될 수 있다.

- 단일 노드에서 쿼리엔진은 동시에 여러 쓰레드에서 오퍼레이터를 실행한다.

    - 클릭하우스는 MonetDB/X100과 동일한 벡터화 모델을 사용한다.

    - 오퍼레이터는 단일 행이 아닌 복수의 행을 생산하고, 전달하고, 소비하여 가상 함수 호출의 오버헤드를 최소화한다.

    - 결과적으로, 모든 하드웨어 리소스를 최대한 사용하고, 쿼리 프로세싱을 노드를 추가하여 수평 스케일링, 코어를 추가하여 수평 스케줄링 할 수 있게 된다.

## SIMD Parallelization

- 여러개의 행을 오퍼레이터간에 전달하면 벡터화의 가능성이 생기게 된다.

    - 벡터화는 수동으로 작성된 intrinsic이나 컴파일러의 자동 벡터화에 기반한다.

- 벡터화가 유리한 코드는 다른 컴퓨트 커널로 컴파일된다.

    - 가장 빠른 커널은 cpuid instruction으로 런타임에서 선택된다.

    - 오래된 시스템에 대한 하위호환성을 지키면서 새로운 하드웨어에서 가속할 수 있는 이유다.

## Multi-Core Parallelization

- 3개의 레인을 가진 물리 오퍼레이터 계획

    [image](https://app.capacities.io/d1cf29da-a5be-492d-839a-e228b21e0129/96c8ed85-f998-4b15-9cf9-f250c41c7876)

- 클릭하우스는 SQL 쿼리를 물리 계획 오퍼레이터 방향성 그래프로 바꾸는데 전통적인 접근을 사용한다.

    - 오퍼레이터 계획의 입력은 데이터를 읽는 특수한 소스 오퍼레이터가 수행한다.

    - 특수한 sink 오퍼레이터가 결과를 원하는 출력 포맷으로 변경한다.

    - 물리 오퍼레이터 계획은 쿼리 컴파일 시점에 워커 쓰레드의 최대값과 소스 테이블의 사이즈에 기반하여 독립적인 실행 레인으로 펼쳐진다.

        - 레인은 데이터를 분해하여 병렬적으로 처리 될 수 있게 된다.

        - 병렬 프로세싱을 최대화하기 위해 레인 최대한 늦게 병합된다.

- 사진의 노드 1번은 페이지 impression을 보여주는 일반적인 OLAP 쿼리

    1. 최초 스테이지에서 3개의 엮이지 않은 페이지가 동시에 필터된다.

    2. 리파티션 교환 오퍼레이터가 동적으로 결과 청크를 첫번째 - 두번째 스테이지 사이에서 라우팅한다.

        - 레인은 첫 - 두번째 스테이지에서 스캔된 범위가 크게 다르면 불균형이 있을수도 있다.

    3. 두번째 스테이지에서, 필터된 row는 리전 ID로 그룹된다.

        - 집계 연산자가 리전 ID를 그룹화 열로 사용하여 로컬 결과 그룹을 유지하며, 각 그룹별 합계와 개수를 avg() 함수의 partial aggregation state로 저장한다.

    4. GroupStageMerge 연산자가 로컬 집계 결과를 글로벌 집계 결과로 병합한다.

        - 연산자는 pipeline breaker로 동작하여, 이 프로세스가 끝날때까지 세번째 스테이지가 시작되지 않는다.

    5. 세번째 스테이지에서, 결과 그룹은 분산 교환 연산자에 의해 3개의 동등한 사이즈 파티션으로 나뉘어지고, AvgLatency로 정렬된다.

        - 정렬은 3단계로 구성된다.

            1. ChunkSort 연산자는 각 파티션의 개별 청크를 정렬한다.

            2. StreamSort 연산자는 2-way merge sort로 결합된 청크의 로컬 정렬 결과를 유지한다.

            3. MergeSort 연산자가 local result를 k-way merge 정렬한다.

- 오퍼레이터는 상태 기계고, 입출력 포트를 통해 상호간 연결이 되어 있다.

    - 오퍼레이터는 need-chunk, ready, done 3개의 상태로 구분된다.

        - need-chunk -> ready : 청크를 오퍼레이터의 입력 포트에 넣는다

        - ready -> done : 오퍼레이터가 입력 청크를 처리하여 출력 청크를 만든다.

        - done -> need-chunk  : 출력 청크가 오퍼레이터의 출력 포트에서 제거된다.

    - 2개의 연결된 오퍼레이터에서 1, 3번의 상태 변경은 결합된 스텝으로만 수행될 수 있다.

        - 소스 오퍼레이터(sink operator)는 ready와 done 두가지 상태만 존재한다.

- 워커 쓰레드는 지속적으로 물리 연산 계획을 순회하며 상태 변환을 수행한다.

    - CPU 캐시 사용량을 높이기 위해 플랜은 동일한 쓰레드가 같은 레인의 연속적인 오퍼레이터를 수행하도록 하기 위한 힌트를 포함한다.

    - 병렬 프로세싱은 스테이지의 disjoint 입력에 대해 수평적으로, 파이프라인 브레이커에 의해 분리되지 않은 스테이지에 수직적으로 발생한다.

    - 새 쿼리가 시작될 때, 동시성 쿼리가 종료되었을 때, subscription이 과하거나 적은 것을 피하기위해 병렬 처리 정도는 쿼리 중에 변경될 수 있다.

        - 하나에서 쿼리 시작에 정의된 워커 쓰레드의 최대 개수까지

- 오퍼레이터는 더 나아가 런타임 쿼리 실행에 2가지 방법으로 영향을 미친다.

    - 오퍼레이터는 동적으로 새로운 오퍼레이터를 생성하고 연결할 수 있다.

        - 집계, 정렬, 조인 알고리즘에서 메모리 사용량이 설정된 쓰레드홀드를 초과하였을 때 쿼리를 취소하는게 아닌 외부에서 전환하기 위해 사용된다.

    -  오퍼레이터는 워커 쓰레드를 비동기로 작동하도록 요청할 수 있다.

        - 외부 데이터를 기다릴 때 워커 쓰레드를 효율적으로 사용하도록 할 수 있다.

- 클릭하우스의 쿼리 실행 엔진과 morsel 주도 병렬처리는 다음과 같은 점에서 유사하다.

    - 레인은 일반적으로 서로 다른 코어 / NUMA 서켓에서 실행된다.

    - 워커 쓰레드는 다른 레인에서 태스크를 훔쳐 수행할 수 있다.

    - 중앙 스케줄링 컴포넌트 대신, 워커 쓰레드가 독립적으로 계획을 순회하여 태스크를 선택한다.

- morsel 주도 병렬 처리와 다르게, 클릭하우스는 병렬 처리를 가능한 한 최대한 사용하고, morsel보다 훨씬 큰 단위로 소스테이블을 분할한다.

    - 이러한 처리가 stall을 만드는 경우도 있지만, 리파티션같은 교환원 오퍼레이터를 자유롭게 쓰는 것이 스테이지간 누적된 불균형을 피하는 것에 유리하다.

## Multi-Node Parallelization

- 쿼리의 소스 테이블이 샤딩되면, 쿼리를 받은 노드의 쿼리 최적화기는 작업을 최대한 다른 노드에서 실행하려 한다.

    - 다른 노드의 결과는 다른 쿼리 계획 포인트에서 통합될 수 있다.

- 쿼리에 따라 리모트 노드는 다음과 같이 작동한다.

    1. 원본 소스 테이블 컬럼을 initiator 노드로 스트림

    2. 소스 컬럼을 필터링하고 생존한 열을 보냄

    3. 필터와 집계 단계를 실행하고 로컬 결과 그룹을 부분 집계 상태와 함께 보냄

    4. 아니면 전체 쿼리를 필터, 집계, 정렬을 포함하여 보냄

- 샤드를 갖고 있는 다른 노드들의 실행 계획 조각

    [image](https://app.capacities.io/d1cf29da-a5be-492d-839a-e228b21e0129/24e06c77-837c-45db-8e38-26ac26b6175f)

    - 이 노드들은 로컬 데이터를 필터링하고 그룹하여, 쿼리가 시작된 노드로 전송한다.

        - 쿼리 시작된 노드의 GroupStateMerge 오퍼레이터가 로컬과 외부 노드 결과를 병합하고, 결과 그룹을 최종 정렬한다.

## Holistic Performance Optimization

- 쿼리 실행에 다른 단계들에서 적용된 중요한 성능 최적화

### Query Optimization

- 최적화의 첫번째 셋은 쿼리의 AST로부터 획득한 시멘틱 쿼리 표현에 있다.

    - 정적 폴딩, 특정 집계함수에서의 스칼라 추출 처리, 공유 subexpression 제거, x=a OR x=b같은 OR 필터 연산을 IN-list 로 변경 등이 해당된다.

- 최적화된 시멘틱 쿼리 표현은 논리적 오퍼레이터 계획으로 이후 변환된다.

    - 논리적 계획 위의 최적화는 필터 푸시다운, 함수 재배치, 스텝 정렬이 포함된다.

        - 어떤 행동이 비용이 가장 클지에 의해 결정된다.

- 최종적으로 논리적 오퍼레이터 계획이 물리적 오퍼레이터 계획으로 변환된다.

    - 이 변환은 연관된 테이블 엔진의 특성을 활용할 수 있다.

    - 머지트리 테이블엔진의 경우

        - 정렬 기준 컬럼이 PK의 접두어를 형성하면 데이터를 디스크 순서로 읽을 수 있고, 정렬 오퍼레이터가 플랜에서 지워질 수 있다.

        - 집계에서 GROUP BY 열이 PK의 접두어를 형성하면 정렬 집계를 사용할 수 있다.

            - 같은 값을 갖지만 정렬된 입력으로 처리하여, 해시 집계에 비해 적은 메모리 사용량과 집계 결과가 프로세스된 후 즉각적으로 다음 오퍼레이터로 전달될 수 있는 장점이 있다

### Query Compilation

- 클릭하우스는 LLVM에 기반한 쿼리 컴파일을 채택하여, 동적으로 인접한 플랜 오퍼레이터를 결합한다.

- 클릭하우스는 expression뿐만 아니라 키가 하나보다 많은 경우의 정렬, 여러 집계 함수의 결과를 컴파일하여 수행하도록 한다.

- 쿼리 컴파일의 장점

    - 가상 호출을 줄일 수 있다.

    - 데이터가 레지스터나 CPU 캐시에 남아있도록 하여 히트레이트를 높일 수 있다.

    - 분기 예측기에 필요한 코드를 줄이도록 한다.

- 런타임 컴파일은 추가적으로 다양한 최적화를 가능하게 한다.

    - 컴파일러에 구현된 논리적 최적화나 peephole 최적화가 가능하다.

    - 로컬에서 가장 빠른 CPU 인스트럭션을 접근할 수 있도록 한다.

- 컴파일은 서로 다른 쿼리가 동일한 일반, 집계, 정렬 expression을 사용할 때 활성화된다.

- 컴파일된 쿼리 오퍼레이터는 캐싱되어 미래 쿼리에 사용된다.

### Primary key index evaluation

- 클릭하우스는 필터링 조건이 결합되어 있는 형태일 때 필터의 조건 중 일부가 PK의 접두어인 경우 PK 인덱스를 이용하여 WHERE 조건을 평가한다.

- PK 인덱스는 사전 순서대로 정렬된 키를 분석한다.

    - PK에 대응되는 필터절은 ternary logic을 따른다.

        - 모두 참이거나, 모두 거짓이거나, 범위에 따라 참 / 거짓이 섞일 수 있다.

        - 섞이는 경우는 범위가 나뉘어 재귀적으로 분석된다.

- 상태 필터에 대해 추가적인 최적화 전략이 있다.

    - 함수는 단조적인 성질을 설명하는 속성을 갖고 있다.

        - 단조적인 성질은 함수가 정렬된 입력 키밸류 범위에 대해 정렬된 결과가 나오는 경우 추론이 가능하게 된다.

    - 몇몇 함수들은 어떤 결과가 나올 것인지에 대한 원상을 연산할 수 있다.

        - 키값을 preimage로 비교하는 방법으로 함수 호출을 상수 비교로 대체한다.

            - toYear(k) = 2024와 k >= 2024-01-01 && k<2025-01-01으로 대체할 수 있다.

### Data skipping

- 클릭하우스는 쿼리 런타임 시점에서 읽기를 피하려 한다. 

    - 추가적으로, 서로 다른 열에 대한 필터는 휴리스틱과 열 통계에 기반한 추정 선택도 순서로 순차적으로 평가된다.

- 하나 이상의 매치되는 행을 가진 데이터 청크만 다음 predicate에 포함될 수 있다.

    - 읽어야 하는 데이터의 양과 수행하는 predicate to predicate 연산 수를 점진적으로 줄인다.

    - 최적화는 최소 하나의 선택된 predicate가 존재할 때만 적용된다.

        - 아니면 모든 predicate를 병렬로 수행할 때보다 쿼리 레이턴시가 악화된다.

### Hash tables

- 집계와 해시 조인을 위한 근본적인 데이터 구조이다.

    - 적절한 타입의 해시 테이블을 적절하게 고르는 것이 성능에 중요하다.

- 클릭하우스는 그룹화 키의 타입, 카디널리티에 따라 30종류 이상의 해시 테이블을 제공한다.

    - 해쉬 함수, 할당자, 셀 타입, 리사이즈 정책까지도 변경할 수 있다.

    - 그룹화하는 열의 데이터 타입, 해시테이블의 cardinality, 추가적인 펙터에 따라 개별적인 쿼리 오퍼레이터에 대해 가장 빠른 해시 테이블이 선택된다.

- 추가적인 최적화가 구현된 해시테이블

    - 해시의 첫 바이트에 기반하여 256개의 서브테이블을 가진 2레벨 레이아웃

        - 많은 키를 가진 셋에 적절하다.

    - 4개의 서브테이블과 다른 함수를 스트링 해시 테이블

        - 스트링의 길이가 서로 다를 때 사용한다.

    - 버킷 인덱스로 키를 직접 접근하는 룩업 테이블

        - 키 개수가 적을 떄 사용

    - 임베딩 해시값을 갖는 경우

        - 비교의 비용이 클 때 빠른 충돌 해결을 위해 사용

    -  예측된 사이즈로 해시 테이블을 생성

        - 런타임에서 통계로 리사이즈가 발생하지 않도록

    - 여러 개의 작은 해시 테이블을 할당

        - 하나의 메모리 슬랩에 생성 / 할당 해제하는것과 동일한 라이프사이클을 갖도록 구성

    - 해시 테이블에 대한 즉각적인 클리어링

        - per-hash-map이나 per-cell 버전 카운터에서 재사용을 위함

### Joins

- 클릭하우스는 원래 기초적인 join 연산만 지원했기 때문에, 과거 대부분의 유즈케이스는 테이블의 비정규화 구성으로 이루어졌었다.

    - 현재에는 SQL에 존재하는 모든 조인 타입을 지원하며, 서로 다른 조인 알고리즘도 지원한다.

        - 해시 조인, 정렬-병합 조인, 빠른 키밸류 룩업이 가능한 테이블엔진의 인덱스 조인

- 조인이 가장 비용이 큰 연산이기 떄문에, 클래식 조인의 병렬 처리 가능한 변형을 제공하는 것이 중요하다.

    - 공간 / 시간적 트레이드 오프가 있으면 최적이다.

- 클릭하우스는 해시 조인을 논블락킹, 공유 파티션 알고리즘을 사용하여 구현했다.

- 셀프 조인으로 구현한 페이지 히트 통계 테이블 연산 과정

    [image](https://app.capacities.io/d1cf29da-a5be-492d-839a-e228b21e0129/165ee197-e2b2-415d-9068-d3cbc63a1ef4)

    - 조인 단계는 3개의 레인으로 나뉘어져, 소스 테이블을 중복없는 3개의 범위로 나누어 처리한다.

    - 글로벌 해시 테이블 대신, 파티션된 해시 테이블이 사용된다.

    - 워커 쓰레드는 해시 함수에 모듈러 연산을 수행해서 빌드 단계에서 각 입력행에 대해 타겟 파티션을 결정한다.

    - 해시 테이블 파티션으로의 접근은 Gather 교환원 오퍼레이터에 의해 동기화된다.

    - 조사 페이즈는 입력 튜플의 타겟 파티션을 찾는다.

        - 알고리즘의 튜플당 2개의 추가적인 해시 연산이 추가되지만, 해시 테이블 파티션 개수에 따라 빌드 단계에서 latch 컨텐션을 크게 줄일 수 있다.

## Workload Isolation

- 클릭하우스는 동시성 컨트롤, 메모리 사용양 제한, I/O 스케줄링을 제공하여 유저가 워크로드 클래스 안에서 쿼리를 독립적으로 실행할 수 있도록 한다.

    - 특정 워크로드 클래스에 대해 공유 자원 제한을 걸어, 서로 다른 쿼리가 서로 영향을 끼치지 않도록 보장한다.

- 동시성 컨트롤은 높은 동시성 쿼리를 처리할 때 쓰레드가 과하게 구독하는 것을 방지한다.

    - 쿼리당 워커 쓰레드의 수는 가용 CPU 코어수에 따라 동적으로 특수한 비율로 조정된다.

- 클릭하우스는 유연한 메모리 사용량 제한을 위해  바이트 사이즈의 메모리 할당을 서버, 유저, 쿼리 레벨에서 추적한다.

    - 메모리 과커밋은 쿼리가 다른 쿼리의 메모리 제한을 보장하면서 보장된 메모리에 추 가적인 양을 쓸 수 있도록 한다.

    - 더 나아가 집계, 정렬, 조인절을 휘나 메모리 사용은 제한되어 있고, 메모리 제한이 초과되면 외부의 fallback  알고리즘으로 이어진다.

- 마지막으로 IO 스케줄링은 유저가 로컬 / 리모트 디스크 접근을 최대 대역폭, in-flight 요청, 정책에 기반하여 제한하도록 한다. 

# Integration Layer

- 실시간 의사 결정 어플리케이션은 효율성과 여러 개의 위치에서 낮은 데이터 접근 레이턴시로 동작한다.

- OLAP 데이터베이스에서 외부의 데이터를 사용하기 위해서는 2가지 전략이 존재한다.

    - 푸쉬 기반 데이터 접근

        - 데이터베이스와 외부 데이터 저장소를 잇는 서드파티 컴포넌트 브릿지

        - ETL 툴들이 이에 해당된다.

    - 풀 기반 모델

        - 데이터베이스가 직접 원격 데이터 소스에 연결하어 데이터를 가져오거나, 리모트 시스템으로 데이터를 전송한다.

    - 푸쉬 기반이 더 견고하고 일반적이지만, 더 큰 아키텍처 자원 사용과 확장 가능성 보틀넥을 남긴다.

    - 데이터베이스가 직접 원격 연결을 수행하면 흥미로운 능력을 제공한다.

        - 로컬 데이터와 리모트 데이터의 조인이다.

        - 전반적인 아키텍처를 단순하게 유지하면서, 인사이트를 위한 시간을 감소시킨다.

- 클릭하우스가 원격 저장소에 접근하기 위해 제공하는 풀기반 모델에 알아보자. 

    - 새로운 모델은 아니며, 2011년에 PG가 이미 구현했다.

    - 다른 데이터 저장소와 스토리지 포맷과의 최대한의 상호 운영성은 클릭하우스의 디자인 목표이다.

        - 2024년 3월 기준 분석 DB중 가장 많은 옵션을 제공한다.

### External Connectivity

- 클릭하우스는 50개 이상의 외부 시스템에 대해 테이블 함수와 엔진 통합을 제공한다.

    - ODBC, MySQL, PostgreSQL, SQLite, Kafka, Hive, MongoDB, Redis와 다양한 데이터 레이크까지

- 카테고리로 나누어보면 다음과 같다.

    [image](https://app.capacities.io/d1cf29da-a5be-492d-839a-e228b21e0129/07c671ac-610d-465a-a374-51ca9eda4255)

- Table Function

    - 외부로 임시적으로 접근하도록 통합

    - SELECT 쿼리의 FROM절에서 실행되어, 원격 데이터에 애드혹 쿼리를 날릴 수 있다.

    - INSERT INTO TABLE 함수와 함께 사용하여 원격 스토리지로 데이터를 삽입할 수 있다.

- Persisted access

    - 리모트 데이터 저장소와 프로세싱 시스템에 영속적인 연결을 생성하는 3개의 메소드가 있다.

    - 테이블 엔진 통합

        - 원격 데이터 소스를 영속적인 로컬 테이블로 통합한다.

            - CREATE TABLE AS로 유저가 테이블 정의를 저장한다.

            - SELECT 쿼리와 테이블 마수로 통합한다.

        - 원격 테이블의 일부 열만 읽어오거나 컬럼명과 대응하는 클릭하우스 타입을 자동으로 인식하는 등의 커스텀이 가능하다.

    - 데이터베이스 엔진 통합

        - 원격 데이터 저장소의 테이블 스키마를 클릭하우스로 매핑한다.

        - 테이블 엔진 통합과 다르게 원격 데이터 저장소가 관계형 데이터베이스여야 하며, DDL에 대한 제한적인 지원이 필요하다.

    - 사전

        - 거의 모든 가능한 데이터 소스에 대해 임의의 쿼리를 사용하여 통합 테이블 기능 또는 엔진을 통해 채올 수 있도록 한다.

        - 데이터를 원격 저장소로부터 고정된 간격으로 풀링하여, 실행시 동작이 활성화 되어 있다.

### Data Formats

- 서드 파티 시스템과 상호작용하기 위해, 현대 분석DB는 어떤 데이터 포맷으로도 데이터를 처리할 수 있어야 한다.

- 클릭하우스는 CSV, JSON, Parquet, Avro, Protobuf를 포함하여 90개 이상의 포맷을 지원한다.

    - 각 포맷은 입력 포맷, 출력 포맷일 수 씨다.

- Parquet같은 분석 기반 포맷은 쿼리 프로세싱에 통합될 수 있다..

    - optimizer가 내장된 통계를 사용할 수 있고, 필터는 압축된 데이터에 계산될 수 있다. 

### Compatibility interfaces

- 네이티브 바이너리 와이어 프로토콜과 HTTP 외에도, MySQL이나 PostgreSQL의 와이어 프로토콜 인터페이스를 제공한다.

    - 클릭하우스 네이티브 연동을 지원하지 않는 상업 어플리케이션에서 클릭하우스 데이터에 접근하도록 할때 유용하다.

# Performance As a Feature

- 내장 성능 분석 툴과 현실 성능 평가 및 벤치마크 쿼리

## Built-in Performance Analysis Tools

- 개별 쿼리나 백그라운드 연산의 병목을 조사하기 위한 다양한 툴이 존재한다.

- 시스템의 테이블에 기반한 획일화된 인터페이스로 툴과 상호작용 할 수 있다.

### Server and Query Metrics

- 서버 레벨의 통계와 쿼리 레벨의 통계가 제공된다.

    - 서버 레벨 통계 : 활성화 파트 개수, 네트워크 처리량, 캐시 히트 레이터

    - 쿼리 레벨 통계 : 읽은 블락 개수, 인덱스 사용률 통계

- 메트릭은 설정된 시간 간격으로 동기적(요청시) 혹은 비동기적으로 연산된다.

### Sampling Profiler

- 서버 스레드의 콜 스택은 샘플링 프로파일러를 이용해 수집된다.

- 결과는 flamegraph 시각화툴같은 외부 툴로 전송될 수 있다.

### OpenTelemetry integration

- OpenTelemetry는 여러 데이터 처리 시스템 간의 트레이싱 데이터 행에 대한 공개 표준이다.

- 모든 쿼리 프로세싱 단계에 대해 OpenTelemetry 로그를 설정 가능한 granularity와 생성할 수 있다.

- 다른 시스템의 OpenTelemetry를 수집하여 분석할 수 있다.

### Explain Query

- 다른 데이터베이스처럼 SELECT를 EXPLAIN하도록 할 수 있다.

    - 쿼리의 AST, 논리적/물리적 오퍼레이터 계획, 실행 시간에 관한 정보를 얻을 수 있다.

## Benchmarks

- 벤치마크는 충분히 현실적이지 않다고 비난받지만, 장/단점을 파악하는데는 유용하다.

- 결과 자체는 원본으로 직접 가서 보도록 하자.

# Related Work

- Sybase IQ, Teradata, Vertica, Greenplum같은 초기 시스템은 큰 비용의 배치 ETL과 온프레미스 환경으로 인한 제한된 유연성이 특징이었다.

- 2010년대에는 클라우드 기반의 DBaaS가 등장하여 스노우플레이크, 빅쿼리, 레드쉬프트 등이 분석 비용과 복잡성을 크게 줄이고, 고가용성과 자동화 스케일링을 제공하였다.

- 최근 분석 실행 커널은 서로 다른 분석, 스트리밍, ML 어플리케이션을 위한 단일화된 데이터 처리를 제공했다.

- 클릭하우스의 목표와 디자인 원칙과 가장 유사한 것은 Druid와 Pinot

    - 빠른 데이터 입력 처리 속도를 통한 실시간 데이터 분석을 목표로 한다.

    - 테이블은 segment라는 수평적 파트로 분리된다.

    - 클릭하우스는 작은 파트를 병합하고 데이터를 줄이는 전략을 사용하지만, Druid와 Pinot은 생성된 후 파트가 병합되지 않고 불변 상태로 남아있는다.

    - Druid와 Pinot은 테이블 생성, 수정, 탐색을 위해 별개의 노드를 사용한다. 

- 스노우 플레이크의 테이블을 마이크로파티션으로 나누는 컨셉은 클릭하우스와 유사하다.

    - 스노우플레이크는 하이브리드 PAX를 영속성을 위해 사용하지만, 클릭하우스는 컬럼 기반이 엄격하게 지켜진다.

    - 경량 인덱스를 자동으로 생성하여 로컬 캐싱과 데이터 프루닝을 강화하여 좋은 성능을 낸다.

    - 클릭하우스의 PK와 유사한 클러스터 인덱스를 생성하여 같은 값을 가진 데이터를 같이 위치시킬 수 있다.

- Photon과 Velox는 복잡한 DBMS의 구성 요소로 사용될 수 있는 쿼리 실행 엔진이다.

    - 쿼리 계획을 입력으로 넣으면, 로컬 노드의 Parquet이나 Array file에서 실행된다.

    - 쿼리 계획을 최적화하지 않고, 런타임 adaptivity 테크닉을 최적화한다.

        - 데이터 타입에 따른 동적 연산 커널 변경 등.

        - 클릭하우스의 계획 오퍼레이터도 다른 오퍼레이터를 런타임에 생성할 수 있다.

            - 쿼리 메모리 소모량에 기반해 외부 집계나 조인 오퍼레이터로 변경할 수 있다.

    - Photon과 Velox의 코드 생성은 C++ 런타임에서 생성된 공유 라이브러리, 클릭하우스는 LLVM의 요청에으로 생성된 compilation API로 직접 상호작용

- DuckDB도 호스트 프로세스에 임베딩되도록 설계하였으나 추가적인 쿼리 최적화와 트랜젝션을 제공한다.

    - 주로 OLAP + 가끔 발생하는 OLTP로 구성된다.

    - 하이브리드 워크로드에서 좋은 성능을 내기 위해 DataBlock 스토리지를 채택했다.

        - 순서가 보장되는 경량 압축 메소드나 frame-of-reference를 제공하여 좋은 성능을 제공한다.

    - 클릭하우스는 append-only 유즈케이스에 최적화 되었다.

        - 블락은 데이터 가지치기를 통해 빠른 속도를 제공한다.

    - Hyper의 MVCC 스키마에 기반한 Serializable 트랜젝션을 제공한다.

        - 클릭하우스는 snapshot isolation만 제공한다.

# Conclusion And Outlook

- 지금까지 클릭하우스의 아키텍처였다.

- 쓰기 최적화 스토리지 레이어, SOTA급 벡터화 쿼리 엔진을 기반으로 클릭하우스는 PB스케일 데이터 셋을 빠른 입력 속도로 처리할 수 있다.

- 스토리지 레이어는 PK 인덱스에 대한 sparse, skipping과 테이블 프로젝션을 기반으로 공격적인 데이터 가지치기를 수행한다.

- 쿼리 프로세싱 레이어는 다양한 테크닉으로 쿼리를 최적화하며, 병렬화하여 모든 서버와 클러스터의 자원을 사용하도록 한다.

- 통합 테이블 엔진과 함수는 다른 DBMS와 데이터 포맷을 seemless하게 연동할 수 있도록 한다.

