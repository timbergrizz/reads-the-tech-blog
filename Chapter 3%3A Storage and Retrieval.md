- 데이터베이스의 스토리지 엔진은 어떻게 데이터를 저장하는가?
	- 데이터가 파일에 저장되어 있을 때, 어떻게 데이터를 가져올 것인가? 매번 풀스캔으로 가져올 수는 없다
	- Hash 형태로 Key와 파일의 오프셋 위치를 저장하면 write 시간은 증가하지만, 빠르게 처리할 수 있다.
- Hash Index
	- 키-값 형태로 메모리에 모든 인덱스를 저장한다.
	- 데이터는 항상 작성하는 방식으로 작동한다.
		- 스토리지가 너무 커지게 되면, 새로운 세그먼트를 만들어 처리한다.
		- 가장 최근의 세그먼트부터 키를 찾으면 데이터를 찾을 수 있다.
		- 여러 개의 세그먼트에서 가장 최신의 키만 포함해서 통합하여 새로운 세그먼트로 정리할 수 있다.
	- 장단점
		- Random Access를 피하고, Sequential하게 처리할 수 있으며 동시성 처리와 오류, 복구가 편해진다.
		- 해시 테이블이 메모리에 맞아야 하며, Range등의 쿼리는 풀스캔 해야해서 비효율적이다.
	- 실제 구현에서 고려할 점
		- CSV보다 바이너리를 사용하는 것이 빠르고 심플한 구조를 만들 수 있다.
		- 키를 삭제할때는, 삭제했다는 기록을 세그먼트에 추가하고 머지 과정에서 키를 없앤다
		- 데이터베이스가 재시작되면 인메모리 해시가 날라가고, 저장된 세그먼트를 통해 다시 해시를 구성한다.
		- 중간에 해시 나가면, 체크섬 확인한다음에 무시한다.
		- 쓰기 스레드를 하나만 두어 동시성 핸들링을 처리할 수 있다.
- SSTable / LSM-Tree
	- Sorted Set Table : 정렬된 형태로 저장된 키-밸류 구조
		- SSTable는 로그 구조이지만,  키를 기준으로 세그먼트 파일을 정렬한다.
		- 각각의 키는 세그먼트 파일에서 한번만 발생한다.
	- Log-Structured Merge Tree : 바이너리 트리로 정렬된 파일 구조를 구현한다.
	- 장단점
		- 해시 테이블보다 세그먼트 머지가 쉽고 효율적이게 된다. (머지소트와 유사한 알고리즘)
		- 모든 키에 대한 인덱스를 찾을 필요 없이, 범위를 기반으로 찾을 수 있게 된다.
		- 읽기 요청은 어차피 범위에 맞는 여러 개의 키밸류 페어를 스캔하기 때문에, 디스크에 작성 이전에 블락 단위로 묶은 후 압축하여 저장할 수 있다.
	- 데이터를 정렬된 구조로 유지하는 법
		- 메모리에 밸런스드 바이너리 트리(레드블랙, AVL  트리)에 정렬된 형태로 저장한다.
		- 쓰기가 발생하면 메모리에 저장된 트리로 입력한다
		- 트리가 Threshold보다 커지면 SSTable 파일로 저장한다.
			- 새롭게 생성된 SSTable이 데이터베이스의 최신 segment가 된다.
		- 읽기 요청은 메모리상의 테이블을 먼저 확인하고, 없으면 최신부터 Segment를 찾는다.
		- 머지와 압축 프로세스를 백그라운드에서 돌려 segment 파일을 합친다.
	- 성능 최적화
		- 이러한 구조에서 데이터베이스에 없는 값을 조회하는 것은 굉장히 오래걸린다.
			- Bloom Filter같은 메모리 효율적인 구조로 데이터의 존재 여부를 확인한다.
		- SSTable을 어떻게 머지하고 간소화할지 순서와 시점에 대한 검토
			- Size-tiered compaction : 새롭고 작은 SSTable을 크고 오래된 파일로 머지
			- Leveled compaction : 키 레인지를 작은 SSTable로 나누고, 오래된 데이터를 분리된 레벨로 보낸다.
		- 기존 아키텍처에 비해 효율적이다.
- B-Tree
	- 로그 기반 인덱스 구조보다 Traditional한 인덱싱 구조이다.
		- 오랫동안 구현되다 보니까 구현의 성숙도가 높다.
		- 트리 구조 쓰는거랑 키가 정렬되는건 SSTable과 같지만, 디자인 철학 자체가 다르다.
	- 데이터베이스를 고정된 사이즈의 Block / Page로 나누고, 한번에 한 페이지를 처리하도록 한다.
		- 각각의 페이지는 다음 페이지로의 주소 혹은 데이터가 위치하는 포인터가 된다.
		- 루트 페이지부터 범위에 맞는 페이지로 내려가면서 leaf page로 이동하여 키를 찾는다.
	- 이미 존재하는 키를 업데이트 하려면, 리프 페이지 찾아서 수정 후, 디스크로 다시 작성한다.
	- 새로운 키를 추가할땐 범위에 맞는 페이지를 찾은 후, 페이지의 빈 공간에 데이터를 추가한다.
		- 빈 공간이 없는 경우, 새로운 페이지를 만들어 분리한다.
	- n개의 인덱스가 있는 B-Tree는 항상 O(log n)타임에 동작한다.
	- B-Tree의 쓰기 동작은 페이지의 디스크에 항상 덮어쓰기 하는 방식으로 구현된다.
		- 오류에 대한 저항성을 위해, 데이터베이스는 WAL log등을 추가적으로 사용한다.
	- 최적화 방법
		- 페이지 수정 후 WAL로그를 유지하는 대신, copy-on-scheme을 사용할 수 있다.
			- 페이지가 수정되면 다른 위치에 새롭게 페이지를 만들고, 부모 페이지 포인터를 수정
		- 전체 키를 저장하지 않고 축약하여 저장하여 페이지 공간을 저장할 수 있다.
			- 범위에 대한 정보만 제공할 수 있으면 된다.
		- leaf page들을 디스크에서 순차적으로 저장할 수 있도록 한다.
			- 근처에 있으면 랜덤 액세스보다 빨라진다.
			- 그렇지만 이렇게 순서를 유지하는 것이 어렵다.
		- 페이지에 바로 옆 형제 포인터를 저장하면, 부모 페이지로 돌아갈 필요가 없어진다.
		- log-structured에서 가져온 아이디어로 디스크 조회를 줄이는 아이디어가 있다.
- Comparing B-Trees and LSMTrees
	- 일반적으로 LSMTree가 쓰기가 빠르고, B-tree가 읽기가 빠르다.
	- B-tree 인덱스는 데이터를 최소 2번씩 써야하는 오버헤드가 있다. (WAL / 인덱스)
		- 로그구조는 머지할때 재작성하긴 하는데, 이러한 amplification이 비교적 적다.
	- 쓰기 중심 어플리케이션에서 디스크에 쓰는 횟수가 많아질수록 느려진다.
		- 이때 LSM트리가 B-Tree보다 amplification이 적고 SSTable이 컴팩트해 더 빠르다.
		- LSM-Tree의 압축률이 더 높아 파일이 작다
	- B-Tree는 Fragmentation을 고려해야 해서 사용 안하는 부분도 붙잡고 있는다.
		- LSM은 고려 안해도 되고 fragmentation을 머지 과정에서 제거하여 오버헤드가 적다.
	- LSM-Tree의 백그라운드 Compaction 프로세스가 퍼포먼스에 영향을 미칠 수 있다.
		- 이것때문에 읽기 성능이 갑자기 튈 수 있고, B-Tree가 더 예측 가능하다.
		- 쓰기가 많이 발생하는 경우, DB가 커질수록 디스크의 대역폭을 더 많이 필요로 한다.
			- 쓰기가 많고 compaction 설정이 고려되어 있지 않으면, 디스크 성능이 못따라간다.
			- 머지가 줄어들고 세그먼트 파일 많아지면서 읽기 성능도 떨어진다.
	- B-Tree는 모든 키가 하나의 위치에 존재해서, Transaction semantic이 강해진다.
	- 우월한 옵션은 없다. 다 테스트 해보는게 맞다.
- Other Indexing Structures
	- Primary Key는 하나의 row만 구분하고, 다른 record는 레퍼런스가 있을 수 있다.
	- 세컨더리 인덱스가 있는 경우도 일반적이다.
		- key-value 인덱스로 쉽게 구성할 수 있는데, 이 경우 키가 unique하지 않다.
	- 인덱스에는 실제 데이터가 저장될 수도 있고, row가 저장된 위치로의 레퍼런스일수도 있다.
		- heap file: Record가 저장되어 있는 위치
		- 키를 바꾸지 않고 업데이트 하려면 heap이 그 전 사이즈보다 크지 않아 그 위치에서 수정될 수 있어야 한다.
	- 인덱스에서 힙까지 가는것도 느려서 인덱스에 직접 row 저장하는 경우도 있다.
		- clustered index 라고 한다.
	- Multi-Column Index
		- 여러개의 컬럼을 묶어서 인덱스를 설정할 수도 있다.
			- Concatenated Index: 여러 개의 필드를 묶어서 하나의 인덱스 키로 묶는다.
			- Multi-dimensional index : 다차원 구조로 인덱스 키를 만든다. 지도 정보에 주로 사용
	- Full-Text Search and Fuzzy Index
		- 위에 인덱스들은 찾는 데이터가 정확히 있다는 것을 가정한다. 비슷한 키를 찾을순 없다.
		- Full-text Search는 하나의 단어로도 검색을 할 수 있도록 구현한다.
			- Lucene은 SSTable로 term dictionary를 구현한다.
				- 인메모리 인덱스가 키가 아니라 문자에 대한 유한 상태 기계다
				- 이 오토마톤이 레벤슈타인 오토마톤으로 바뀔 수 있다.
	- Keeping everything in memory
		- 다 디스크에서 제한이 걸려버리니까 걍 램에다 다 때려박자!
		- 캐시를 타겟으로한 인메모리 키밸류 스토리지는 재시작하면 다 날아간다.
			- 캐시 타겟 아닌 경우 durability를 챙기기 위해 여러가지 전략을 사용한다.
				- 디스크에 저장한 후 켤때 다시 로드해도, 일단 인메모리 스토리지로 본다.
		- 인메모리의 장점은 디스크에서 읽는 이점때문에 빠른게 아니다
			- 인메모리 데이터 구조를 디스크로 인코딩하는 과정이 없어져서 빠른거다.
			- 인메모리 데이터베이스는 성능을 넘어서 디스크 기반으로는 구현하기 힘든 더 다양한 데이터 모델을 제공한다.
- Transactional Processing or Analytics?
	- 트랜젝션 프로세싱과 분석 프로세싱은 필요한 성능이 다르다.
		- 분석은 많은 record를 분석할 수 있어야 하고, 일부 컬럼만 필요로 한다.
	- OnLine Transaction Processing
		- 트랜젝션을 다루기 위한 데이터베이스
		- 적은 컬럼수의 읽기, Random Access와 낮은 레이턴시의 쓰기가 주로 발생한다.
		- 주로 엔드 유저에게 어플리케이션을 통해 제공한다.
		- 가장 최신의 데이터만을 필요로 하고, GB~TB단위의 데이터셋이 된다.
	- OnLine Analysis Processing
		- 데이터분석을 다루기 위한 데이터베이스
		- 많은 Row 읽기, Bulk Import와 Event Stream이 주로 발생한다.
		- 주로 내부 분석가에게 의사 결정을 위해 제공된다.
		- 시간대별로 발생한 내역을 모두 확인하고, TB-PB단위의 데이터셋이 된다.
	- Data Warehouse
		- 분석을 제공하기 위해 분리된 데이터베이스를 Data Warehouse라고 한다.
		- 기업에는 많은 OLTP 시스템을 운영하고, 이러한 시스템은 트랜젝션을 낮은 지연시간으로 구동하고자 한다.
			- 데이터 웨어하우스는 분석가들이 필요한 데이터를 OLTP에 영향 없이 뽑아내기 위해 주로 사용된다.
			- OLTP에서 데이터를 추출, 분석에 용이한 형태로 변경하여 웨어하우스로 저장한다
				- Extract-Transform-Load (ETL)
		- 분리된 데이터 웨어하우스를 사용함으로서, 분석 패턴에 맞게 최적화할 수 있게 된다.
		- 데이터 웨어하우스는 일반적으로 관계형으로 구성되고, SQL을 사용한다.
			- 그래서 OLTP 시스템이랑 생긴건 비슷한데, 쿼리 패턴이 다르기 때문에 내부 구현이 달라진다.
	- Stars / Snowflake Patterns
		- 데이터 웨어하우스는 OLTP에 비해 비교적 일정한 형태의 데이터 모델을 사용한다.
		- Fact는 하나의 이벤트로 캡쳐되고, 따라서 Fact 테이블이 엄청나게 커진다.
		- Fact에 대한 속성(dimension)들이 존재하고, 이를 다른 테이블에 저장한 후 레퍼런스로 Fact로 저장한다.
			- 테이블 관계를 시각적으로 표현하면 별모양이라 star schema가 된다.
				- Fact가 Dimension의 레퍼런스를 저장하는 형태가 된다.
		- SnowFlake 패턴은 Star 패턴에서 속성들을 더 쪼개서 Normalize한거다.
			- 근데 보통은 Star가 더 심플해서 많이 쓴다.
	- Column-Oriented Storage
		- Fact는 페타바이트 단위의 데이터가 있고, 많은 수의 컬럼 중 일부 4-5개의 컬럼만 사용하는 경우가 많다.
			- 분석에서는 많은 row를 일부 컬럼만 사용한다.
		- row 기준으로 파일을 묶는게 아니라, col 기준으로 묶고 row를 일정한 순서로 저장한다.
			- 이렇게 되면, 매번 모든 column을 호출할 필요가 없어진다.
			- row가 일정한 순서대로 위치하기 때문에, 데이터의 일관성을 보장할 수 있다.
		- Column Compression
			- 적은 수의 일정한 데이터가 중복하게 발생하는 경우, 데이터를 압축하기 유리해진다.
			- bitmap-indexed 형태로 컬럼을 압축하면, 데이터를 압축하고 처리하기 빨라진다.
				- IN, AND등의 Logical Operator에서 bitwise 연산이 가능해져서 빨라진다.
		- Data warehouse는 많은 row를 스캔하고, 디스크에서 메모리로 가는 병목이 제일 크다.
			- CPU Cache를 사용하여 효율적으로 CPU Cycle을 사용하려는 시도가 많다
				- L1 캐시에 들어가도록 컬럼 데이터를 압축하는 등의 최적화를 사용한다.
		- Sort Order in Column Storage
			- SSTable처럼 정렬 순서를 결정하고, 인덱싱 메카니즘을 적용할 수 있다.
			- 서로 다른 쿼리들은 서로 다른 정렬 순서로 이득을 볼 수 있으니까, 정렬 순서에 따라 데이터를 여러개씩 저장하는 방식도 사용할 수 있다.
			- Columna 구조에서 여러 개의 sort order를 가는건 Row 구조에 세컨더리 인덱스 거는거랑 비슷하다.
				- 로우 기반은 데이터를 한번만 저장하고 세컨더리 인덱스로 포인터를 넣는다.
				- 컬럼 기반은 인덱스 개수에 따라 데이터를 여러번 저장한다.
		- Writing to Column-Oriented Storage
			- B-tree처럼 Update-in-place는 암축때문에 불가능하고, 컬럼을 새로 다 써야 한다.
			- LSM-Tree로 저장하는 것도 방법이다.
				- 모든 쓰기는 일단 인메모리로 저장되고, 그다음에 쌓이면 그걸 내리는 방법
	- Aggregation
		- 모든 데이터 웨어하우스가 Columna일 필요는 없다.
			- 근데 Column DB가 분석용으로 쓰기 위한 쿼리에서 빠르다.
		- 연산이 필요할 때, 연산값을 미리 저장해두는 방식으로 캐싱을 수행할 수 있다.
			- 연산 결과를 미리 저장해두고, 필요한 연산 결과만 사용한다.
				- OLTP는 업데이트되면 계산 결과 다 업데이트 쳐야하니까 비용 큰데, 분석DB는 어차피 배치처리고 업데이트보다 쓰기가 많아서 괜찮다.
			- 여러개의 컬럼에 대한 값이 필요한 경우, 다차원 배열을 이용해 이러한 값을 캐싱한다.
			- Raw데이터에 대해 쿼리하는것보다는 유연성이 떨어진다.