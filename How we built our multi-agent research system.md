- 출처 : [How we built our multi-agent research system](https://www.anthropic.com/engineering/built-multi-agent-research-system)
- Benefits of a multi-agents system
	- 리서치는 다음에 어떤 단계를 수행해야 할지 예측하기 어려운 열린 결말의 문제들을 해결한다
		- 프로세스가 동적이고 패스에 의존적이기 때문에 복잡한 주제에 대한 탐색을 고정된 경로로 하드코드할 수 없다
		- 이러한 예측 불가능성이 인공지능을 research task에 적합한 도구로 만들어준다.
			- 리서치는 피벗하거나 수직적인 연결에 대한 탐색을 요구하기도 한다.
	- 모델은 여러 턴동안 자동으로 동작할 수 있어야 하고, 지금까지의 탐색을 통해 어떤 방향으로 가야할지 정할 수 있어야 한다.
		- 선형적인 one-shot 파이프라인으로 이를 해결할 수 없다.
	- 검색의 정수는 압축이다. 거대한 코퍼스에서 인사이트를 찾아낼 수 있다.
		- 서브에이전트들은 병렬적으로 컨택스트 윈도우 안에서 압축을 가능하게 한다.
			- 질문의 서로 다른 면을 동시에 조사하여, 가장 중요한 토큰을 리드 리서치 에이전트로 보내어 처리한다.
			- 각 서브에이전트는 관심사가 분리되어, 다른 툴, 프롬프트, 탐색 경로를 바탕으로 작동한다.
	- 지능이 일정 정도를 넘어서면, 멀티 에이전트 시스템은 퍼포먼스를 스케일하기 위한 중요한 방법이 된다
		- 하나의 인간은 15만년전보다 똑똑해졌지만, 인간 사회는 정보 사회에 지수적으로 능력이 상승했다.
			- 에이전트 개개인의 지능보다 항상 단체가 더 큰 성과를 달성할 수 있다.
		- 내부 평가에 따르면, 너비 우선 탐색을 사용하는 멀티 에이전트 시스템이 최고 성능의 단일 에이전트 시스템 성능의 92%에 달하는 결과를 보였다.
	- 멀티 에이전트 시스템이 작동하는 이유 하나는 문제를 풀기 위한 충분한 토큰을 사용할 수 있기 때문이다.
		- BrowseComp 평가에서 토큰 사용량이 그 자체로 성능의 85%의 분산을 설명했다.
			- 툴 콜링, 모델 선택이 다른 외부 요소다.
		- 이 연구는 분리된 컨택스트 윈도우로 에이전트에 태스크를 분배하여 병렬 사고의 농력을 강화한다는 가설을 입증했다.
		- 멀티 에이전트 아키텍처는 하나의 에이전트로 한도를 초과하는 태스크에 대해 효과적으로 토큰 사용량을 스케일링한다.
	- 단점은, 일반적인 채팅에 비해 9배정도로 토큰을 엄청나게 빠르게 사용한다는 것이다.
		- 경제적인 부분을 위해, 멀티 에이전트 시스템은 성능 향상폭과 비용의 트레이드오프를 계산해야 한다.
	- 몇몇 도메인은 모든 에이전트에 대해 하나의 컨택스트를 공유하거나 에이전트 사이에 의존성을 필요로 하는데, 이는 현대의 멀티에이전트 시스템과 잘 맞지 않는다.
	- 멀티 에이전트 시스템은 병렬을 잘 사용할 수 있는 작업, 컨택스트 윈도우를 초과하는 정보량, 많은 수의 복잡한 툴과 동작해야 할 때 잘 작동한다.
- Architecture overview for Research
	- 리서치 시스템은 Orchestrator-worker 패턴을 사용한다.
		- ![1203befc0b33726c45692ac40f764022f4de1bf2-4584x2579.webp](../assets/1198befc0b33726c45692ac40f764022f4de1bf2-4584x2579_1752479796643_0.webp)
		- ((687455b7-275e-4ac6-8f7e-52eeaee5e530))
		- 리드 에이전트가 분리된 작업을 코디네이트하고, 작업을 할당받은 특수화된 서브 에이전트들이 병렬적으로 작업을 수행한다.
	- 유저가 쿼리를 입력하면, 리드 에이전트가 이를 분석하여 전략을 세우고, 서브 에이전트들에 다른 면들을 동시에 조사하도록 한다.
		- 서브에이전트들은 검색을 통해 정보를 수집하는 지능형 필터로 작동한다.
		- RAG를 이용한 과거에는 static retrieval을 이용했다.
			- 청크들을 fetch 한 다음에 입력 쿼리에 가장 가까운 청크를 골라 응답 생성에 사용했다.
		- 멀티 에이전트 아키텍처는 동적으로 관련된 정보를 찾아, 새로운 탐색 경로에 적용하고, 결과를 종합하여 높은 퀄리티의 응답을 생성한다.
		  ![11ed4595a6fb96f9036991a3c6699c3237e0921f4-4584x4584.webp](../assets/6ed4595a6fb96f9036991a3c6699c3237e0921f4-4584x4584_1752480719336_0.webp)
			- 멀티 에이전트 리서치 시스템의 워크플로우
			- 유저가 쿼리를 입력하면, 시스템은 LeadResearcher 에이전트를 만들어, 반복적인 research process로 진입한다.
				- LeadResearcher는 접근을 따라 사고하고, 메모리로 계획을 저장하여 컨택스트를 유지한다.
				- 컨택스트 윈도우가 25만 토큰을 넘어서면 자동으로 truncate되므로, plan을 유지하는 것이 중요하다.
			- 이후 특수한 Subagent를 생성하여, 특정한 리서치 태스크를 수행하도록 한다.
				- 각 Subagent는 독립적으로 웹 검색을 수행하고, [Interleaved thinking](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#interleaved-thinking) 결과를 평가하여 응답을 리드리서치에 반환한다.
			- 응답이 반환된 후 LeadResearcher는 이러한 결과를 합성하여 더 연구가 필요한지 판단한다.
				- 필요한 경우 Subagent를 추가로 생성하여 동일한 과정을 반복한다.
				- 필요하지 않은 경우 루프를 나와 CitationAgent로 모든 탐색 결과를 보내어 참조가 필요한 모든 부분을 확인한다.
			- 최종리서치 결과가 유저에게 리턴된다.
- Prompt Engineerubg abd evaluations for research agents
	- 멀티 에이전트 시스템은 싱글 에이전트 시트메과 다른 중요한 포인트이 존재한다.
		- 코디네이션에 대한 복잡성이 급격하게 증가하는것도 포함한다
	- 각 에이전트는 프롬프트로 트리거되기 때문에 프롬프트 엔지니어링이 에이전트를 개선하기 위한 최우선의 레버였다.
	- 에이전트를 프롬프트 할 때 다음과 같은 원칙을 지키도록 하였다.
		- Think like your agents
		  logseq.order-list-type:: number
			- 프롬프트에서 반복을 수행하려면, 그 영향을 이해해야 한다
				- 그래서 정확한 프롬프트와 툴을 만들고, 콘솔을 사용하고 에이전트가 어떤 단계롤 작동하는지를 보았다.
				- 이를 통해 실패한 경우들을 확인할 수 있었다.
					- 에이전트가 충분한 데이터를 확보하였는데도 계속 데이터를 수집하는 경우
					- 너무 말이 많은 검색 결과를 사용하는 경우
					- 적절하지 않은 툴을 사용하는 경우
				- 효과적인 프롬프팅은 에이전트의 정확한 멘탈 모델을 만들고, 가장 효과적인 변화가 된다.
		- Teach the orchestrator how to delegate
		  logseq.order-list-type:: number
			- 시스템에서 리드 에이전트는 쿼리를 서브태스크로 나누고 이를 서브에이전트들에 설명한다.
			- 각 서브에이전트는 목적, 출력 포맷, 툴에 대한 가이던스, 사용할 소스, 작업 바운더리가 필요하다.
				- 자세한 작업 설명이 없으면 에이전트는 중복된 작업을 하고, 공백을 남기거나, 중요한 정보를 찾는 것을 실패하는 등의 에러가 발생한다.
					- 리드 에이전트에게 "반도체 부족에 대한 리서치"같은 짧은 지시를 했을 때, 모호해서 서브에이전트가 잘못 해석하거나 다른 에이전트들과 동일한 검색을 수행했다.
		- Scale effort to query complexity
		  logseq.order-list-type:: number
			- 에이전트는 서로 다른 태스크에 대해 적절한 정도의 노력을 모르기 때문에, 프롬프트에 스케일 룰을 도입했다.
				- 단순한 사실 탐색은 하나의 에이전트가 8-10번의 툴 콜링, 직접적인 비교는 2-4개의 에이전트가 10-15번의 툴 콜링, 복잡한 연구에 대해서는 명확히 책임이 분리된 10개의 에이전트
			- 이러한 명시적인 가이드라인은 리드 에이전트가 자원을 효율적으로 분배하고, 간단한 쿼리에 과투자하지 않도록 했다.
		- Tool design and selection are critical
		  logseq.order-list-type:: number
			- 에이전트-툴 인터페이스는 인간-컴퓨터 인터페이스만큼 중요하다.
			- 적절한 툴을 사용하는 것은 효율적이고, 굉장히 중요하다.
				- MCP 서버로 외부 툴을 사용하는 경우, 사용해보지 않은 툴이 엄청나게 다양한 퀄리티의 설명으로 들어와 문제가 섞이게 된다.
			- 에이전트에게 휴리스틱을 주어 해결했다.
				- 사용 가능한 툴을 조사한다.
				  logseq.order-list-type:: number
				- 사용자 의도와 관련된 툴을 선택한다.
				  logseq.order-list-type:: number
				- 탐색을 위해서는 일반 검색을, 특정 행동을 위해서는 특수화된 툴을 사용한다.
				  logseq.order-list-type:: number
			- 툴에 대한 잘못된 설명은 완전히 잘못된 패스로 이어질 수 있어, 각
		- Let agents improve themselves
		  logseq.order-list-type:: number
			- LLM 모델이 프롬프트 엔지니어링을 기가막히게 한다.
				- 프롬프트와 실패한 경우를 넣으면 왜 프롬프트가 실패했는지와 개선 방법을 제시해준다
			- 툴을 테스트하는 에이전트도 만들었을 때 잘 작동했다.
				- 툴 사용을 시도하고, 툴 설명을 재작성하여 실패를 막았다.
				- 툴을 반복적으로 테스트하면서, 에이전트가 직접 키 뉘앙스와 버그를 찾아내었다.
				- 이러한 과정을 통하여 대부분의 실수를 피하도록 하여 새로운 설명을 사용하는 에이전트의 작업 시간이 45% 감소하였다.
		- Start wide, then narrow down
		  logseq.order-list-type:: number
			- 검색 전략은 사람의 리서치를 모방해야 한다.
				- 전반적인 그림을 탐색한 후, 세부적인 내용을 파고 들어야 한다.
			- 에이전트는 응답 몇개 없는 너무 긴 특정한 쿼리를 기본적으로 탐색하곤 한다.
				- 이러한 경향성을 에이전트가 짧고 광범위한 쿼리로 어떤게 검색 가능한지 찾도록 한 후, 집중을 파고들도록 하여 해결했다.
		- Guide the thinking process
		  logseq.order-list-type:: number
			- 추가적인 토큰으로 시각적인 사고 과정을 출력하는 클로드의 확장 사고 모드는 조작 가능한 스크래치 패드로 작동할 수 있다.
				- 리드 에이전트는 접근을 계획하고, 작업에 적절한 툴 선택을 위해 사고를 사용할 수 있다.
			- 테스트 결과 확장 사고 모드가 지시 이행, 사고, 효율성을 개선하였다.
			- 툴 사이에 사고를 사용하여 퀄리티를 평가하고, 공백을 인지하며, 다음 쿼리를 결정했다.
				- 서브 에이전트가 작업에 적응하기 효율적으로 만들었다.
		- Parallel tool calling transforms speeds and performance
		  logseq.order-list-type:: number
			- 복잡한 리서치 작업은 자연스럽게 많은 소스를 탐색하게 된다.
				- 초기 에이전트들은 연속적으로 탐색을 수행했는데, 엄청나게 느렸다.
			- 속도를 위해 7가지 병렬화를 도입했다.
				- 리드 에이전트는 8-5개의 서브에이전트를 병렬로 돌렸다.
				- 서브에이전트는 8개 이상의 툴을 병렬로 돌렸다.
			- 이러한 변화는 복잡한 쿼리에 대한 리서치 시간을 95%까지 줄일 수 있었다.
	- 강압적인 규칙보다 좋은 휴리스틱을 갖도록 하는것에 집중하였다.
		- 숙련된 사람이 어떻게 작업을 리서치하는지 학습하였고, 프롬프트로 이를 인코딩했다.
			- 어려운 질문을 작은 단위 작업으로 분해
			- 찾은 결과의 퀄리티를 평가
			- 새로운 정보를 통해 탐색 결과를 조정
			- 깊이(하나의 토픽을 디테일하게 탐색)와 너비 (다양한 토픽을 병렬로 탐색) 중 어떤 것에 집중해야 할지를 판단
	- 명시적인 가드레일을 설정하여 에이전트가 통제 불가 상테가 되는 것을 막고, 의도하지 않은 사이드 이펙트를 방지하였다.
	- 관측 가능성과 테스트 케이스를 가진 빠른 반복 루프를 구성하는 것에 집중하였다.
- Effective evaluation of agents
	- 좋은 평가는 신뢰성 있는 AI 개발을 위해 필수적이며, 에이전트도 다르지 않다.
	- 멀티 에이전트 시스템은 평가를 위헤선 특수한 과제들이 있다.
		- 일반적인 평가는 AI가 입력 X를 줬을때 경로 Y를 따라 출력 Z를 생성할 것이라 생각한다.
		- 멀티 에이전트 시스템은 이런 방법으로 작동하지 않고, 동일한 시작점에서도 에이전트는 목표 도달을 위해 전혀 다르지만 유효한 경로를 사용할 수도 있다.
			- 하나의 에이전트는 8개의 소스를, 다른 에이전트는 10개를 탐색할 수도 있고, 다른 툴을 사용해 동일한 정답을 찾을 수도 있다.
	- 우리는 어떤 단계가 "옳은지" 모르기 떄문에, 당연히 옳은 단계를 밟았는지 확인할 수 없다.
		- 대신, 우리는 유연한 평가 방법이 필요하다.
	- 다음과 같은 단계를 따랐다.
		- Start evaluating immediately with small samples
		  logseq.order-list-type:: number
			- 에이전트 개발 초기에는 비교적 얻기 쉬운 성과들로 인해 변화가 드라마틱했다.
				- 이렇게 변화가 드라마틱한 경우, 테스트 케이스 몇개만으로 변화를 감지할 수 있다.
			- 25개 정도의 실제 사용 패턴을 반영한 쿼리로 테스트를 시작했다.
				- 이러한 쿼리를 테스트하여 변화의 영향을 확인할 수 있었다.
			- 적은 수의 예시가 있는 작은 스케일의 테스트로 시작하는것도 충분하다.
		- LLM-as-judge evaluation
		  logseq.order-list-type:: number
			- 리서치 결과는 자유 형식의 텍스트이고, 정답이 없기 때문에 프로그래밍적으로 평가하기 어렵다.
			- LLM에게 결과를 평가하도록 하였다.
				- 출처에 작성된 내용을 반영했는지 정확도
				- 인용에 명시된 내용이 같은지 정확도
				- 요청된 모든 내용을 커버하는지를 판단하는 완전성
				- 신뢰할 수 있는 주요 출처를 사용했는지 여부를 판단하는출처의 퀄리티
				- 툴 호출의 효율성
			- 한번의 LLM 호출로 5-1 사이의 pass-fail grade를 평가하도록 하였을 때 가장 일관되고 인간의 판단과 유사하게 나왔다.
		- Human evaluation catches what automation missees
		  logseq.order-list-type:: number
			- 평가로 찾지 못한 엣지 케이스를 사람들이 찾았다.
				- 익숙하지 않은 쿼리에 대한 할루시네이션, 시스템 오류, 소스 선택 편향 등
			- 초기 에이전트가 SEO 최적화된 컨텐츠를 높은 우선순위의 개인 블로그, 학술 PDF보다 선호하는 현상을 발견하고, 소스 퀄리티를 판단하는 휴리스틱으로 이를 해결했다
	- 멀티 에이전트 시스템은 프로그래밍 없이 즉각적인 행동을 수행한다.
		- 리드 에이전트의 작은 변경으로 서브에이전트가 어떻게 달라질지 예측하기 어렵다
	- 그렇기 때문에, 이러한 에이전트에 대한 최선의 프롬프트는 경직된 지시 사항이 아닌, 작업 범위의ㅣ분리와 문제 해결의 접근, 비용 최적화가 담긴 협업을 위한 프레임워크이다.
		- 적절하게 이를 달성하기 위해서는 주의 깊은 프롬프팅과 툴 디자인, 견고한 휴리스틱, 관측 가능성, 타이트한 피드백 루프를 필요로 한다.
		- [research agent 프롬프트 쿡북](https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents/prompts) 보세용
- Production reliability and engineering challenges
	- 전통적인 소프트웨어에서, 버그는 기능을 망가트리거나, 성능을 악화시키거나, 장애로 이어진다
	- 에이전트 시스템의 경우는 작은 변화가 큰 행동 변화로 이어지고, 따라서 복잡한 에이전트에 대해 코드를 수정하기 어려워진다.
	- Agents are stateful and errors compound
		- 에이전트는 긴 시간동안 작동하고, 여러 번의 툴 콜링동안 상태를 유지한다.
			- 이는 코드를 실행하고 에러를 처리할 때 내구성이 필요하다는 것.
		- 에러가 발생하면, 처음부터 작동시키기엔 너무 비싸다.
			- 대신 시스템에서 에이전트가 에러 발생 지점부터 시작할 수 있도록 구성한다.
		- 에러를 graceful하게 다루기 위해 모델의 지능도 사용한다.
			- 툴에 오류가 발생했다는 것을 알려주고, 이걸 적응하도록햐나 작동 잘했다.
		- 클로드로 만든 AI 에이전트에 재시도 로직같은 세이프가드와 레귤러 체크포인트를 추가했다.
	- Debugging benefits from new approaches
		- 에이전트는 동적으로 선택을 하며, 동일한 프롬프트여도 작동마다 deterministic하지 않다.
			- 디버깅이 굉장히 어려워진다.
			- 예를 들어, 유저가 에이전트에 명확한 정보를 찾지 못했다고 리포트 할 때 왜인지를 찾을수 없다.
				- 에이전트가 잘못된 검색 쿼리를 쐈나? 잘못된 원본을 사용했나? 툴 실패했나?
		- 프로덕션에 full tracing을 추가하여 왜 에이전트가 실패했고, 시스템적으로 이슈를 해결할 수 있었다.
			- 표준 관측 가능성을 넘어서, 에이전트의 선택 패턴과 상호 작용 구조도 모니터링하였다.
			- 이러한 높은 레벨의 관측 가능성은 문제의 근본 원인을 진단하고, 예측되지 않은 행동을 발견하며, 일반적인 실패에 대응할 수 있었다.
	- Deployment needs careful coordination
		- 에이전트 시스템은 프롬프트, 툴, 실행 로직이 거의 동시에 작동하는 stateful한 거미줄이다.
			- 업데이트할 배포할 때, 에이전트가 그 과정 안에 있을 수 있다.
		- 현재 있는 에이전트를 깨지 않으면서 배포를 수행할 수 있도록 하였다.
			- 한번에 모든 에이전트를 새 버전으로 바꿀 수 없고, 따라서 작동중인 에이전트를 방해하지 않도록 점진적으로 트래픽을 새 버전으로 이전하는 레인보우 배포를 선택했다.
	- Synchronous execution creates bottleneck
		- 현재 우리의 리드 에이전트는 서브에이전트를 동기적으로 실행하고, 서브에이전트 끝나는거 기다렸다 이어나간다.
			- 이는 코디네이션을 간단하게 하지만, 에이전트 사이의 정보 플로우의 병목을 만든다.
			- 하나의 에이전트가 검색 완료까지 기다리도록 해서 서브에이전트가 시작 안되면, 서브에이전트 코디네이팅 안되고, 시스템이 블락되는 경우가 발생할 수 있다.
		- 비동기적 실행이 추가적인 병렬 처리를 도입할 수 있다.
			- 에이전트들이 동시에 일하고, 필요할 때 새로운 서브 에이전트를 만들도록 할 수 있다.
			- 하지만 서브에이전트 사이의 코디네이션, 상태 일관성, 에러 전파에서 대해서 추가적인 챌린지를 만든다.
		- 모델이 길고 복잡한 리서치를 수행할 수록, 퍼포먼스 성능 향상이 복잡성을 정당화할 것.
- Conclusion
	- 에이전트를 만들때, 마지막 한 걸음이 보통 제일 어렵다.
		- 개발자가 작업하던걸 신뢰성 있게 프로덕션에 올리려면 엄청나게 많은 엔지니어링을 필요로 한다.
		- 에이전틱 시스템의 혼합된 에러는 전통적인 소프트웨어의 조그마한 이슈도 에이전트 전체에 영향을 미칠 수 있다.
			- 이런 모든 이유로, 프로토타입과 프로덕션은 예상한것보다 엄청나게 차이가 크다.
	- 이러한 챌린지에도, 열린 결말의 리서치에는 에이전트 시스템이 효과적이라는 것이 증명되었다.
	- 멀티 에이전트 리서치 시스템은 주의 깊은 엔지니어링, 테스팅, 강건한 동작 예제, 리서치 제품 엔지니어링 팀의 강한 콜라보레이션으로 큰 스케일에서도 작동할 수 있다.
- Appendix : Tips for multi-agent system
	- End-state evaluation of agents that mutate state over many turns
		- 여러 턴의 대화에서 영속적인 state를 수정하는 에이전트를 평가하는것도 유니크한 챌린지다.
			- 읽기만 하는 리서치 태스크와 다르게, 각 액션이 연속적인 단계에 대한 환경을 바꾸고, 의존성을 바꾸기 떄문의 전통적인 평가 방법이 다르다.
		- 각 턴에서 분석하기보단, end-state를 평가하는 것에 집중하였다.
			- 특정 프로세스를 따랐는지 확인하기보단 적절한 최종 state에 도달하였는지를 확인
		- 이러한 접근은 에이전트가 같은 목표에 대한 다른 접근을 사용할 수 있으며, 의도한 출력을 낼 수 있다.
		- 복잡한 워크플로우에선, 평가를 모든 중간 스텝이 아닌 특정한 상태 변경이 발생하는 견고한 체크포인트로 설정할 수 있다.
	- Long-horizon conversation management
		- 프로덕션 에이전트는 10번 이상의 턴을 도는 대화에 엮인다.
			- 컨택스트 매니지먼트 전략이 필요해진다.
		- 대화가 길어지면, 일반적인 컨택스트 윈도우가 충분하지 않아지고, 압축과 메모리 전략이 필요해진다.
		- 에이전트가 완료된 워크페이즈를 요약하고, 중요한 정보를 외부 메모리에 저장한 후 새로운 태스크를 수행하도록 구성하였다.
			- 컨택스트가 한계에 다다르면, 에이전트는 새로운 서브에이전트를 생성하여 컨택스트를 비우고, 주의깊은 전달을 통해 연속성을 확보한다.
		- 더 나아가, 리서치 계획같은 정보를 이전 정보가 아닌 메모리에서 가져오도록 할 수 있다.
		- 이러한 분산 접근은 컨택스트 윈도우를 넘치는것을 막으면서, 상호작용에 대해 대화의 연관성을 유지한다.
	- Subagent output to a filesystem to minimize the 'game of telephone'
		- 직접적인 서브에이전트 출력은 메인 코디네이터를 통과하여 출력될 수 있다.
		- 서브에이전트가 리드 에이전트를 통해서만 소통하도록 하는것이 아닌, artifact system을 구현하여 특수화된 에이전트가 영속적인 출력을 생성할 수 있도록 한다.
			- 서브에이전트가 외부 시스템에 작업을 젖아할 수 있도록 하고, 가벼운 레퍼런스만 잔달하도록 하는 것
			- 멀티 스테이지 과정동안 정보가 손실되는 것을 막을 수 잇으며, 큰 출력을 복사하는 동안 발생하는  오버헤드를 막을 수 있다.
		- 코드, 리포트, 데이터 시각화 등의 구조화된 출력에서 잘 작동한다.
			- 서브에이전트의 특수한 프롬프트가 코디네이터 통과하는것보다 더 나은 출력을 낼 때 유용하다.