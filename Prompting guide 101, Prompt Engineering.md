- 출처
	- [A quick-starthandbook for effective prompts](https://services.google.com/fh/files/misc/gemini-for-google-workspace-prompting-guide-101.pdf)
	- [Prompt Engineering](https://www.kaggle.com/whitepaper-prompt-engineering)
- # A quick-starthandbook for effective prompts
	- 4개의 메인 영역으로 구분하여 프롬프트를 작성하면 좋다
		- Persona : 어떤 사람이 질의하는 것 처럼 설정할 것인가?
		- Task : 어떤 작업을 수행허도록 할 것인가?
		- Context : 어떤 맥락과 사전 정보에서 갈 것인가
		- Format : 어떤 형태로 데이터를 출력할 것인가?
		- You are a program manager in [industry].(Prompt) Draft an executive summary email (Task) to [persona] based on [details about relevant program docs] (Context). Limit to bullet points (Format).
	- Quick Tips
		- 자연어를 사용한다. 다른 사람에게 말하듯이 자연어를 사용한다.
		- 자세하게 반복해서 말한다. 어떤걸 수행해야하는지, 최대한 많은 컨텍스트를 말하도록 한다.
		- 복잡성을 피하고, 간결하게 말한다.
		- 대화처럼 구성한다. 응답이 예상과 다르면 프롬프트를 파인튠하고, 이어지는 프롬프트로 개선된 결과를 얻도록 한다.
		- Gemini의 경우, Document를 사용하도록 한다.
		- 모델 자체가 프롬프트를 작성하도록 한다.
	- Leveling up your prompt writing
		- 여러개의 연관된 태스크를 수행할 때, 이걸 쪼개서 사용한다.
		- 결과를 생성할 때 특정한 요구 조건이 있으면, 프롬프트에서 디테일하게 제약 조건을 설정한다.
		- 에이전트의 상상력을 발휘시키기 위해 역할을 부여하는 방법을 사용할 수 있다..
		- 결과에 대해 개선하기 위해 인공지능 모델에 피드백을 요청하도록 할 수 있다.
		- 의도한 청자에 맞도록 프롬프트에서 톤앤 매너를 설정한다.
		- 원하는대로 응답이 나오지 않을 때, 프롬프트를 리뷰하고 수정하는 과정을 반복하여 응답을 개선한다.
- # Prompt Engineering
	- LLM 모델에서는 텍스트 프롬프트가 모델이 특정한 출력을 만들기 위해 사용하는 입력이다.
		- 엔지니어나 사이언티스트가 아니어도 프롬프트를 작성할 수 있지만, 효율적인 프롬프트를 생성하는건 복잡하다.
		- 사용하는 모델과 그 학습데이터, 모델 설정, 단어 선택, 문장과 톤, 구조, 문맥등 많은 요소가 효율성에 영향을 미친다.
			- 불충분한 프롬프트는 응답의 정확도를 낮추고 모호하게 하며, 모델의 능력을 가린다.
		- 프롬프트 엔지니어링은 좋은 응답을 받기 위한 반복적인 프로세스이다.
	- Prompt Enginnering
		- LLM은 예측 모델처럼 연속적인 텍스트를 입력으로 받아 학습된 데이터를 바탕으로 출력을 예측한다.
			- 프롬프트를 작성할 때, 사람은 LLM이 정상적인 결과를 반환하도록 작성한다.
			- 프롬프트 엔지니어링은 LLM이 정확한 응답을 생산하도록 하는 프롬프트를 만드는 것.
				- 최적의 프롬프트를 찾고, 프롬프트의 길이를 최적화 하고, 글 구조와 스타일을 평가하는 구조이다.
				- 이러한 프롬프트는 텍스트 요약, 정보 추출, 질의응답, 텍스트 분류, 번역, 코드 생성, 코드 도큐멘테이션등에서 사용될 수 있다.
					- 프롬프트 엔지니어링은 모델 선택으로 시작하고, LLM의 많은 Config도 고려하여야 한다.
	- LLM Output configuration
		- 모델을 선택했으면 모델의 Configuration을 결정해야 한다.
			- 대부분의 LLM은 다양한 설정가능한 옵션이 있고, 효율적인 프롬프트 엔지니어링에서는 이를 최적화 하는 것을 필요로 한다.
		- Output length
			- 응답에서 생성할 토큰의 개수 중요한 설정 중 하나이다.
			- 응답 토큰 개수 줄인다고 해서 출력 스타일이 달라지는게 아닌, 리밋 치면 응답생성 멈추는것
				- 짧은 출력이 필요하다면, 프롬프트를 이에 맞추어 수정해야 할 수 있다.
			- ReAct(Reasoning and Acting) 구조에서 의미없는 토큰이 생성되지 않도록 사용할 수 있다
			- 많은 토큰을 생성하는건 많은 연산을 수행한다는 것이고, 지연과 비용 증가로 이어진다.
		- Sampling Controls
			- LLM은 하나의 토큰을 예측하는게 아니라, 어떤 토큰이 가능할지 토큰과 확률 리스트를 생성한다.
				- LLM의 단어 사전의 토큰들이 확률을 갖게 된다.
				- 이러한 토큰에 대한 확률은 이후 샘플되어 다음 토큰의 결정에 사용된다.
			- Temperature, top-k, top-p는 가장 일반적으로 사용되는 샘플링 변수이다.
			- Temperature : 토큰 선택에서의 랜덤성을 조절한다.
				- 낮으면 랜덤성이 낮아져 결정적인 응답이, 높으면 다양하고 예측못한 응답이 나온다.
					- Temperature가 0이면 항상 가장 높은 확률의 토큰이 선택되어 deterministic 해진다. Greedy Decoding
				- Temperature가 높을수록, 모든 토큰이 다음 토큰이 될 가능성이 높아진다.
				- Gemini의 temperature는 softmax로 이해할 수 있다.
					- 낮은 temp는 낮은 softmax temp로, 하나의 확률 높은 선택지를 강조한다.
					- 높은 temp는 높은 softmax temp로, 다양한 범위의 temp가 선택될 수 있도록 한다.
			- Top-K and Top-P
				- 다음 토큰으로 올 수 있는 것들을 몇개나 고를건지 샘플링하는 파라미터이다.
				  id:: 686e2be8-f4de-44e6-a420-0a0d46651bf0
				- Temperature처럼 랜덤성과 생성된 텍스트의 다양성을 결정한다.
				- Top-K개의 가장 가능성 높은 토큰을 선택한다.
					- Top-K가 많으면 더 다양한 출력 결과가 나오고, 적으면 다양성 줄어든다.
						- top-K 1이면 이것도 Detereministic한다. Greedy Decoding
				- Top-P는 누적분포에서 P값이 넘지 않는 것만 고르도록 한다.
					- P = 0 이면 Greedy decoding, 1이면 모든 vocabulary를 고르도록 한다.
				- 두 변수를 모두 조정하며 실험하여 최선의 결과를 얻는 값을 찾는게 최선이다.
		- Putting it all together
			- 샘플링 파라미터를 설정하고, 토큰 개수를 설정하는 것은 어플리케이션과 원하는 출력에 의해 결정된다.
				- 선택한 모델이 이러한 샘플링 세팅을 어떻게 결합하는지도 이해해야 한다.
			- Vertex AI의 경우 temperature, top-k, top-p가 모두 사용 가능하면, Top-K와 Top-P에 해당되는 모든 토큰이 후보로 선택되고, 이후 Temperature가 적용된다.
			- Temperature가 사용 불가능한 경우, top-K, top-P로 결정된 토큰에서 랜덤으로 고른다.
			- 극단적인 세팅에서는 다음과 같이 작동한다
				- Temp 0으로 하면, top-K / top-P은 의미 없고 가장 확률 높은 토큰이 선택된다.
				- Temp가 반대로 높아지면 top-K, top-P로 선택된 것 중에 랜덤으로 들어간다.
				- top-K를 1로 설정하면 temp랑 top-P에 상관 없이 확률 가장 높은 하나만 선택 된다.
				- top-K를 크게 설정하면 LLM 사전의 모든 단어가 다음 후보가 된다.
				- top-P를 0으로 하면, top-P에 맞는 가장 확률 높은 토큰만 선택된다.
				- top-P를 1로 하면, 0보다 높은 확률은 모두 다음 후보로 선택된다.
			- 일반적으로 temp .2, top-P .95, top-K 30을 많이 쓴다.
				- 더 창의적인 답변을 원하면 (.9, .99, 40)
				- 덜 창의적인 답변을 원한다면 (.1, .9, 20)
				- 항상 하나의 질문에 하나의 답변을 원한다면 temp 0으로 설정하면 된다.
			- Repitition loop bug
				- 모델이 Cycle에 갇혀 같은 filter word만 생성하는 것이다.
				- 낮거나 높은 temp에서 다른 이유로 모두 발생할 수 있다,
					- 낮은 온도에선 모델이 너무 deterministic해서, 확률 높은 길로만 가니 같은 path로 가는 경우 루프가 발생한다.
					- 역설적으로 높은 온도에서는 출력이 너무 랜덤성이 강해 이전 상태로 돌아가버려 루프가 될 수 있다.
					- 두 경우 모두 모델의 샘플링 프로세스가 stuck되어, 의미없는 출력 뱉게 된다.
	- Prompting techniques
		- LLM은 지시를 따르도고, 질의를 이해하고 응답할 수 있도록 튠되지만, 완벽하지 않다.
			- 프롬프트가 명확할수록 LLM의 예측이 개선된다.
			- 추가로, 좋은 응답을 위해 LLM이 학습되는 방식에 따라 생기는 이점을 사용하는 방법도 있다.
		- General prompting / zero shot
			- zero-shot은 task에 대한 설명과 시작할 텍스트를 제공하는 가장 단순한 타입 프롬프트
				- example이 없어서 zero-shot
			- 제로샷이 작동하지 않으면, 예제나 데모를 보여주는 one-shot, few-shot을 사용한다.
			- Creativity가 필요 없는 경우로, temperature를 낮게 설정한다.
		- One-shot & Few-shot
			- 프롬프트에 예제가 들어있으면, AI가 질문을 이해하기 좋다.
			- one-shot은 하나의 예시를, few-shot은 여러개의 예시를 제공한다.
				- few-shot은 모델이 따라야 하는 패턴을 알도록 할 수 있다.
				- 예제의 개수는 일의 복잡도, 결과의 퀄리티, 선택한 모델의 능력으로 결정된다.
			- 단순한 task에서는 3-5의 예시면 충분한데, 복잡한 예시에선 더 넣어야 한다.
				- 모델의 입력 길이에 따라서 더 적은 예시만 사용해야 할 수도 있다.
			- 예시를 고를때, 수행하고자 하는 태스크에 대한 예시를 제공한다.
				- 예시는 다양해야하고, 퀄리티 높은 잘 작성된 글이어야 한다.
				- 작은 오류도 모델 출력의 결과물을 혼란스럽게 만들 수 있다.
				- 다양한 입력에 대해 robust한 출력을 만들고 싶으면, 예제에 edge case를 추가한다.
		- System, contextual and role prompting
			- System Prompting
				- 전반적인 컨텍스트와 모델의 목적을 제공한다.
				- 모델이 어떤 동작을 수행할지 큰 그림을 제공한다.
				- 모델의 근본적인 능력과 목적을 정의한다.
				- 특정한 요구사항이 있는 출력을 생성할때 좋다.
					- 시스템 프롬프트 자체가 시스템에 추가적인 태스크를 제공하는 것
				- 응답 JSON으로 반환하도록 하면 따로 JSON으로 변환할 필요 없고, 구조적인 응답을 하도록 하여 할루시네이션을 줄일 수 있다.
				- 안전과 공격성 또한 시스템 프롬프트로 제어할 수 있다.
			- Contextual Prompting
				- 현재 대화, task의 특정한 디테일과 백그라운드 정보를 제공한다.
				- 모델이 질문의 뉘앙스를 이해하고, 응답을 생성하는것을 돕는다.
				- 현재 태스크, 입력에 집중되어 있는 즉각적이고, task-specific한 프롬프트
				- AI가 빠르게 유저의 요청을 이해하고 더 정확하고 연관성 높은 응답을 생성할 수 있도록 한다.
			- Role Prompting
				- 모델이 어떤 캐릭터, 아이덴티티를 가질지 부여한다.
					- 이를 통해 질문과 더 관련되고, 중요한 정보가 담긴 응답이 나오도록 할 수 있다.
				- 모델이 특정 롤을 기준으로 일정한 지식, 행동으로 행동하도록 할 수 있다.
				- 모델의 출력 스타일과 보이스를 설정하고, specificity와 성격을 설정한다.
				- 롤을 정의하면 톤, 스타일, 전문성을 가진 영역을 설정하여 응답의 퀄리티, 연관성, 효과를 향상시킨다.
		- Step-back Prompting
			- 모델에게 처음 특정 태스크에 대해 제너럴한 질문을 고려하고, 이를 녹여내 응답을 하도록 하는 방법
			- 모델이 특정 질문의 응답을 생성하기 전에 연관성 있는 기반 지식의 활성화와 이에 대한 사고 과정을 수행하게 됨
			- 질문에 대한 기초 원칙을고려함으로서, 모델은 더 정확하고 인사이트가 있는 응답을 하게 됨
				- Step-back 프롬프팅은 LLM이 비판적으로 사고하고, 기반 지식을 새롭고 창의적인 방법으로 적용할 수 있도록 함
				- 최정 프롬프트를 LLM 파라미터의 지식에서 활용하도록 한다.
			- 특정 세부사항이 아닌 일반적인 내용을 고려하면서 모델 응답의 편향을 줄일 수 있다.
			- 원하는 질문에 대한 응답을 생성하도록 하기 전에 기초적인 내용을 질문하도록 하면 된다.
		- Chain of Thought: "Let's think 'step by step'"
			- Chain of though는 모델이 사고 과정을 생성하여 사고 능력을 향상시키는 방법이다.
				- 모델이 더 정확한 답변을 하도록 할 수 있다.
			- few-shot과 결합하여 복잡한 응답에 대해 zero-shot보다 개선된 응답을 하도록 할 수 있다.
			- 효과적이고, 큰 노력을 필요로 하지 않는다.
			- 다양한 use-case에서 유용하다.
		- Self-consistency
			- 모델이 다양한 자연어처리 태스크에서 좋은 성과를 냈지만, 여전히 모델 파라미터 크기로 극복할 수 없는 제한이 있는 것 처럼 보인다.
				- CoT 보면 사람처럼 단계로 사고하는 것 처럼 프롬프팅 할 수 있다.
				- 하지만 CoT는 단순한 greedy decoding 전략으로, 효과를 줄이는 방법을 쓴다.
			- Self-consistency는 샘플링과 majoirity voting을 결합하여 가능한 사고 회로를 생성하고, 가장 일정한 답을 고르도록 한다.
			- Self-consistency는 정답에 대해 pseudo probability likehood를 주지만, 비용이 크다.
			- 다음과 같은 단계를 따른다.
				- 동일한 프롬프트를 통해 다양한 사고 회로를 생성한다. 이때 모델의 창의성을 강조한 세팅을 한다.
				- 각각의 응답에서 정답을 추출한다.
				- 가장 일반적인 응답을 선택한다.
			- 여러 개의 창의성 있는 Chain of Thought를 생성하고, 가장 일반적인 응답을 선택하여, 더 일관된 정답을 고를 수 있게 된다.
		- Tree of thoughts (ToT)
			- CoT 프롬프트의 아이디어를 일반화 한것이다.
			- 한번에 하나의 체인이 아닌 동시에 여러개의 다른 reasoning path를 수해하도록 하는것.
				- 이러한 접근은 ToT가 탐구가 필요한 복잡한 작업을 잘 수행할 수 있도록 한다.
		- ReAct (Reason & Act)
			- 모델과 외부 툴을 결합하여 모델이 외부 틀로 액션을 수행할 수 있도록 하는것
				- 외부 API에 요청을 보내 데이터를 가져오는 등의 동작을 하도록 할 수 있다.
			- ReAct는 사람이 현실에서 어떤 행동을 하는지를 모방한다.
				- 모델이 사고를 수행한 후, 액션 수행 계획을 세우고 액션을 수행하도록 구성된다.
				- 액션을 수행하고 결과를 확인하고, 결과를 바탕으로 사고를 업데이트하고 새로운 계획을 세운다.
				- 모델이 문제의 해결책을 찾을 때 까지 반복한다.
		- Automatic Prompt Engineering
			- 이쯤되면 프롬프트 작성하는거 복잡하다고 느낄 수 있다.
				- 그래서 프롬프트를 작성하도록 모델에게 프롬프트를 작헝하면 된다.
			- 모델이 프롬프트를 만들도록 하고, 평가한 뒤에, 가장 좋은 프롬프트를 쓰도록 하면 된다.
		- Code prompting
			- 특별한 내용 없음.
			- Prompts for writing code
			- Prompts for explaining code
			- Prompts for translating code
				- 이런 translation은 프롬프트를 재활용 하기 좋다.
			- Prompt for debugging and reviewing code
			- Multimodal prompting
				- 코드는 일반적인 LLM을 쓰지만, 멀티모달은 다른 얘끼다.
					- 텍스트에만 쓰는게 아니라 사진, 영상 등 여러 형태의 입력을 넣을 수 있다.
	- Best Practices
		- 예시를 제공하라
			- 어떻게 작동할 지 가르치는 강력한 티칭 툴로 작용하기 때문에, one-shot, few-shot으로 예시를 제공하는 것이 좋다.
			- 모델은 예시를 읽고 응답을 예시에 맞추어 정돈한다.
		- 단순하게 디자인하라.
			- 프롬프트는 간결하고, 깔끔하여 이해하기 좋아야 한다.
			- 복잡한 언어를 사용하지 말고, 필요 없는 정보는 제공하지 않는 것이 좋다.
		- 명확하게 출력을 제공하라
			- 원하는 출력에 대해 명확하게 정의하여 제공한다.
		- 제약사항보다는 지시사항을 제공한다.
			- 지시사항은 모델이 무엇을 해야 하는지 응답의 원하는 형태, 스타일, 내용이 담긴다.
			- 제약사항은 모델이 하지 말거나, 피해야 하는 행동을 제시한다.
			- 많은 제약사항을 설정하기보다 긍정적인 지시사항을 프롬프트에 제공하는것이 효과적이라는 연구가 있다.
				- 지시사항은 원하는 응답 자체를 자세히 요구하지만, 제약 사항은 무엇을 원하는지를 모르게 한다.
				- 제약 사항이 모델의 상상력을 제한할 수 없다.
			- 위험하거나 공격적인 컨텐츠를 만들지 않게는 유용하다.
			- 가능하다면, 어떤 것을 수행해야 하는지가 담긴 긍정적인 지시 사항을 사용하자.
			- 지시사항에 모델이 어떤 것을 수행하도록 원하는 우선순위를 설정하는 것으로 시작하자
				- 제약 사항은 안전, 명확성, 특정 의도에서만 사용하자.
		- 최대 토큰 길이를 잘 컨트롤하라
			- 프롬프트 안에 어느정도의 길이로 응답을 생성할 것인지를 작성하자.
		- 프롬프트에 변수를 사용하라
			- 프롬프트를 재사용하고 여러 입력에 대해 동적으로 사용하도록 하기 위해 변수를 사용한다.
			- 변수는 반복 입력을 줄일 수 있도록 한다.
				- 동일한 정보를 여러 프롬프트에 사용해야 한다면, 변수를 저장해두고 여러 프롬프트에서 그걸 재사용할 수 있다.
		- 입력 포멧과 글쓰기 스타일에 대해 실험을 해보라
			- 모델 종류, 설정, 프롬프트 포맷, 단어 선택에 따라 응답 달라지므로, 프롬프트를 특성별로 실험해보는 것이 좋다.
		- 분류 작업의 경우 Few-shot 프롬프팅에서 예시의 분류 클래스를 섞어둔다.
			- 특정 순서로 넣어 오버피팅되는 것을 방지하기 위함
			- 예시 6개 정도 넣어서 정확도 측정해보고 시작해보면 좋다.
		- 모델 업데이트에 적응하라
			- 새로운 모델들을 실험하고, 새로운 모델들의 기능을 더 사용할 수 있도록 프롬프트를 수정하라
		- 응답 포맷에 대해 실험해보라
			- 프롬프트 입력 포맷 전에, 출력 포맷을 실험해보라.
				- 창의력이 필요 없는 태스크는 출력을 JSON, XML등으로 출력하도록 해봐라
			- 응답을 이렇게 출력하도록 하면 다음과 같은 장점이 있다.
				- 항상 동일한 스타일로 응답을 생성한다
				- 필요한 데이터에 집중할 수 있다.
				- 할루시네이션이 줄어든다.
				- 관계성에 주의한 응답을 만들게 된다
				- 데이터 타입을 설정할 수 있다.
				- 정렬도 할 수 있다.
			- JSON Repair
				- JSON 형태롤 응답 뱉으면 장점이 많지만, 단점도 있다.
				- JSON의 구조는 어플리케이션에서는 파싱에 유리하지만, 플레인 텍스트보다 더 많은 토큰을 필요로 한다.
				- JSON의 중복이 출력 윈도우를 다 써서, 출력 중간에 끊겨 문제가 발생할 수도 있다.
				- json-repair같은 파이썬 툴을 이용하여 이를 수정하도록 할 수 있다.
			- 스키마를 정의하고 동작시키라.
				- 구조화된 JSON을 응답 생성에 사용하는것도 좋지만, 입력도 JSON 스키마 만들고 맞춰넣으면 좋다.
				- JSON 스키마는 예상 입력에 대한 구조를 정의하고, 이에 맞추어 입력을 넣도록 한다.
					- 스키마를 제공함으로서 모델에 어떤 입력이 들어올지 청사진을 제공하여, 연관된 정보에 대해 집중하고 입력 값의 오해를 방지할 수 있다.
				- 특히 데이터의 양이 많을 때 모델이 연관된 필드에만 집중하도록 할 수 있다.
		- 다른 프롬프트 엔지니어들과 같이 실험하라
		- CoT Best Practices
			- 사고 과정 토큰 생성 후 정답을 생성하도록 정답을 사고 과정 뒤에 넣도록 해야한다.
			- CoT와 self-consistency에서 입력에 대해 사고와 분리된 최종 정답을 생성할수 있도록 한다.
			- CoT prompting에는 Temp 0으로 설정해라
				- CoT는 기본적으로 Greedy Decoding에 기반하고, 가장 높은 확률을 고르도록 하므로, 최종 응답을 만들때 하나의 답변만 나오도록 한다.
		- 시도한 프롬프트들을 문서화하라
			- 어떤 프롬프트가 성공했는지 어떤 모델과 세팅에서 잘 나오고, 못 나왔는지 기록해둬라.
			- 조그마한 프롬프트의 단어 선택, 문장 구조 차이도 결과값의 차이로 이어질 수 있다.
			- 다음과 같은 템플릿 괜찮다. ![image.png](../assets/image_1752134970851_0.png)
				- 프롬프트의 버전 트래킹, 결과값의 평가, 피드백 캡쳐 정도 추가해두면 좋다
			- RAG 시스템에선 어떤 입력된 컨텐츠, 청크 설정, 출력 등도 확인할 수 있어야 한다.
			- 프롬프트가 완벽하다고 느껴진다면 이를 프로젝트 코드베이스에 저장하고, 코드와 분리된 파일로 저장하여 관리하기 편하도록 한다.
			- 프롬프트 엔지니어링은 반복적인 프로세스로, 다른 프롬프트들을 만들고, 분석하고, 이를 문서화하는 과정으로 원하는 응답을 얻을 수 있다.
		-