- 어플리케이션은 어떻게 다른 어플리케이션에 데이터를 전달할까?
- 데이터 포맷이나 스키마가 바뀌면 어플리케이션 코드도 바뀌어야 하지만 어플리케이션에 바로 적용할 수 없다.
	- 서버 사이드에서 롤링 업데이트를 수행해, 구버전과 신버전이 동시에 존재할 때는 어떻게 처리해야 할까?
	- 업데이트를 설치하지 않는 유저로 구버전 클라이언트가 있으면 어떻게 할까
- 호환성
	- Backward Compatibility : 구버전에서 작성한 데이터를 새로운 버전에서 읽을 수 있어야 한다.
	- Forward Compatibility : 새로운 버전에서 작성한 코드를 구버전에서 읽을 수 있어야 한다.
	- Backward Compatibility는 괜찮은데, Forward Compatibility가 문제다.
- Formats For Encoding Data
	- 메모리 내부에서는 데이터가 특정한 자료구조로 저장된다.
	- 네트워크로 데이터를 보내거나 할땐 데이터를 바이트 배열로 인코딩 해서 사용한다.
	- 따라서 인메모리 표현과 바이트 시퀀스 표현간의 번역이 가능해야 한다.
		- 인메모리 -> 바이트 시퀀스를 인코딩 / 바이트 시퀀스 -> 인메모리를 디코딩이라 한다
- Language-Specific Formats
	- 보통은 프로그래밍 언어 자체에 인코딩 지원이 포함되어 있긴 한데, 문제가 있다
		- 프로그래밍 언어에 너무 묶여있어서 다른 프로그래밍 언어와의 호환이 문제다.
			- 다른 언어에서는 데이터를 불러오는게 굉장히 어려워진다.
		- 동일한 타입으로 데이터 복원하려면 디코딩할때 임의의 클래스를 인스턴스화 할 수 있어야 한다
			- 보안 문제로 이어진다.
		- 버저닝된 데이터나 효율성 같은건 고려 안된다
- JSON, XML And Binary Variants
	- JSON / XML / CSV 는 텍스트로 구성되어 사람이 읽을 수 있는 표준 인코딩
		- 얘도 문제가 있다.
			- XML과 CSV는 숫자 인코딩에서 string과 number를 구분하기 애매하다.
			- JSON이랑 XML은 유니코드 문자는 잘 지원하는데, 바이너리로 저장은 지원 안한다.
				- Base64로 인코딩 해서 바이너리 저장하기도 한다.
		- XML, JSON에 스키마 지원이 있긴 한데 배우기가 좀 복잡하다.
		- CSV는 스키마 지원이 없어서 어플리케이션이 행, 열을 어떻게 해석할지 결정한다.
	- Binary Encoding
		- 데이터가 조직 내에서만 사용하면 덜 알려졌어도 더 작고 파싱 빠른 바이너리 인코딩을 쓸 수 있다.
		- JSON, XML 둘다 바이너리 포맷보다 많은 용량을 사용하고, 그래서 바이너리 인코딩을 하려는 시도가 있다.
			- 보통은 데이터 모델은 유지하도록 바이너리 인코딩을 한다.
			- 스키마를 미리 정의하지 않기 때문에 스키마의 필드명도 바이너리에 포함해야 한다.
		- Thrift, Protocol Buffer는 미리 정의한 스키마를 사용한다.
			- 인코딩한 데이터를 읽으려면 스키마가 필요하다.
			- 스키마를 정의하고 코드 생성 툴로 스키마와 맞는 struct를 생성한다.
			- 인코딩된 데이터에는 field name이 들어가지 않고, 대신 tag를 사용한다.
			- Field tags and schema evolution
				- 스키마가 미리 정의되어 있던 경우에도 스키마가 바뀔 수 있다.
					- 스키마가 태그 번호랑 데이터 타입 기반으로 정의되어 있기 때문에, 이걸 바꿔서 안된다.
						- 태그를 바탕으로 오래된 소스는 새로운 데이터에서 필요한 부분만 읽어서 forward compatibility 성립
						- 태그를 바탕으로 새로운 소스도 예전 데이터를 읽을 수 있어 backward compatibility가 성립
					- 필드 추가할때 이걸 필수 필드로 만들면 안된다.
					- 필드 삭제할때도 반대로 생각해서 하면 된다.
		- Avro
			- 사람이 읽을 수 있는 스키마와 기계가 읽을 수 있는 스키마 2개의 스키마를 사용한다.
			- 태그 넘버가 존재하지 않는다.
				- 기계 스키마 기준으로 데이터를 파싱한다.
			- The writer's schema and the reader's schema
				- 데이터 인코딩할때 알고 있는 버전으로 인코딩 하고, 이를 writer's schema라고 한다.
				- 디코딩할때 끌어다 쓰는 버전은 reader's schema라고 한다.
				- Avro는 이 두개가 같을 필요가 없다.
					- 두 스키마를 나란히 보고 writer's schema에서 나온 데이터를 reader's schema로 변환하여 이러한 차이를 해결한다.
				- Schema evolution rules
					- 호환성을 유지하기 위해서 기본값이 존재하는 필드만 추가하고, 삭제해야 한다.
						- 기본값이 없으면 backward compatibility가 깨진다.
						- 프로그래밍 언어들 중 null을 타입들의 기본값으로 사용할 수 있는 경우도 있다.
							- Avro는 이거 아니어서 union으로 처리.
				- Writer's Schema : Reader는 어떤 writer's schema로 인코딩 됐는지 어떻게 알 수 있을까
					- 많은 레코드가 담긴 큰 파일 : 그냥 writer's schema를 파일 앞에 넣는다.
					- 개별적으로 레코드가 작성된 DB : 인코딩된 레코드에 버전 정보를 포함한다.
					- 네트워크로 레코드 전송 : 데이터를 전송하기 전 스키마 버전을 결정, 연결동안 사용한다.
				- Dynamic generated Schemas
					- Avro는 스키마에 태그 넘버를 포함하지 않아, 동적 스키마 생성이 쉬워진다.
					- DB 스키마가 변경되면 맞춰서 Avro 스키마 만들고 데이터 다시 export하면 된다.
						- protobuf같은거 쓰면 스키마 수정할 때 태그넘버 다시 다 직접 할당해야한다.
				- Code generation and dynamically typed languages
					- 동적 프로그래밍 언어에선 컴파일때 타입체크 안해서 코드 생성에 별 문제 없다.
					- 타입체크 하는 언어도 Avro가 제공한다.
		- The Merits of Schemas
			- Thrift, protobuf같은 바이너리 인코딩 포맷은 스키마를 작성한다.
			- 스키마를 사용한 바이너리 인코딩은 스키마 없는 바이너리보다 다음과 같은 장점이 있다.
				- binary JSON 변형보다 데이터가 컴팩트하다.
				- 스키마는 문서 자체로도 가치가 있다. 이게 디코딩에 필요해서 최신 상태를 유지하기 쉽다.
				- 스키마 데이터베이스를 유지하는게 배포 전에 호환성 확인에 도움이 된다.
				- 정적 타입 언어에서 코드 생성해서 컴파일타임에 타입 보장한다.
- Models of Dataflow
	- 호환성은 데이터를 인코딩하는 프로세스와 디코딩하는 프로세스간의 관계이다.
		- 추상적인 아이디어고, 다양한 종류의 프로세스들이 존재한다.
	- Dataflow Through Database
		- DB로 데이터 작성하는 프로세스가 인코딩 / DB에서 데이터를 읽는 프로세스가 디코딩을 한다.
		- Backward Compatibility 없으면 과거에 쓴 데이터를 새로운 버전에서 못 읽는다
		- 여러 버전의 어플이 동시에 실행되는 환경이 발생할 수 있어, Forward Compatibility도 필요하다.
			- 스키마에 필드를 추가하고, 새 버전의 코드가 새로운 데이터를 작성했을 때 이걸 구버전에서도 정상적으로 작동시킬 수 있어야 한다
		- Different values written at different times
			- 데이터베이스에는 먼 과거, 가까운 과거에 작성한 데이터가 혼재한다.
			- Rewriting, 마이그레이션을 할 수 있긴 한데 큰 데이터셋에서 이건 비용이 크다.
				- 보통은 심플하게 필드 추가되면 기본 값으로 null 추가한다.
		- Archival storage
			- 웨어하우스로 저장하거나 백업 뜰때는 가장 최근의 스키마를 이용하여 인코딩한다.
	- Dataflow Through Services : REST and RPC
		- 클라이언트 - 서버 구조를 기준으로 생각하자.
			- 이때 클라이언트는 웹브라우저일수도 있지만, 서비스 그 자체일 수도 있고 어플리케이션일수도 있다.
		- 서비스와 데이터베이스는 유사하다. 클라이언트로부터 데이터를 받고 쿼리하도록 한다.
		- 마이크로 서비스 아키텍처는 어플리케이션을 독립적으로 만들어서 배포하고 진화하기 편화하게 하는거다.
			- 이 상황에선 구버전 / 신버전이 혼재한다고 생각해야 한다.
		- Web Services
			- REST / SOAP
				- REST는 프로토콜이 아니고, HTTP에 만들어진 디자인 철학이다.
					- HTTP 기능을 적극적으로 사용한다.
				- SOAP는 네트워크에 요청을 보내기 위한 XML 기반의 프로토콜이다.
					- HTTP에서 독립되려 하고, 기능을 피하려고 한다.
					- 사람 읽도록 만든게 아니라서 직접 관리하기 어렵고 툴 지원에 의존한다.
		- The Problems with remote procedure calls
			- 로컬 함수 콜은 성공 실패가 예측이 되는데, 네트워크때문에 RPC는 예측이 안된다.
			- 로컬 함수 콜은 결과, 익셉션, 리턴 없음 셋중 하난데 네트워크는 타임아웃이 존재한다.
			- 실패한 네트워크 요청을 다시 시도했을 때, 동작은 여러번 수행하고 응답만 사라질 수도 있다.
			- 네트워크는 레이턴시가 있어 지연 시간도 따로 고려해야한다.
			- 로컬 함수를 호출할 때는 포인터 쓰면 되는데, 네트워크는 파라미터 네트워크로 다 보내야 한다.
			- 클라이언트와 서비스가 다른 언어 쓰면 RPC가 데이터타입 변환할 수 있어야 한다.
		- Current Directions for RPC
			- 새로운 프레임워크는 리모트 요청이 로컬 함수 콜이라는 걸 알아야 한다는 것.
			- 바이너리 인코딩 쓰는 RPC 프로토콜은 REST, JSON보다 성능이 좋다.
				- 대신 REST가 JSON보다 디버깅하기 편하다.
				- 같은 조직, 특히 같은 데이터센터 안에서는 REST보다 바이너리 포맷을 많이 쓴다.
		- Data encoding and evolution for RPC
			- RPC 스키마에서 backward / forward compatibility는 다음과 같이 달성한다.
				- Thrift, gRPC, Avro RPC는 호환성 룰을 만들어서 처리한다.
				- SOAP는 XML 스키마로 한다.
				- RESTful API는 JSON으로 달성한다.
			- API버전이 어떻게 작동해야 하는지에 대한 규정은 없다.
	- Message-Passing Dataflow
		- 클라이언트와 서버 사이의 요청에 메시징 브로커같은 버퍼를 두는 구조를 말한다.
		- direct RPC에 비해 다음과 같은 장점이 있다.
			- 작동하지 않거나 과부하됐을 때 버퍼로서 작동하여 시스템 신뢰도를 높인다.
			- 프로세스가 크러쉬났을 때 데이터 다시 전송해서 데이터가 유실되는 것을 막는다.
			- 발송자가 수신자의 IP / 포트넘버같은 정보를 알 필요가 없다.
			- 하나의 메시지가 동시에 여러 개의 수신자를 가질 수 있다.
			- 발송자와 수신자를 디커플링할 수 있게 된다.
		- 일반적으로 메시지 전송 통신은 단방향 통신이라, 발송자는 응답을 받지 않는다.
		- Message Brokers
			- 일반적으로 토픽 / 큐로 발신자가 데이터를 보내고, 브로커는 메시지가 컨슈머에게 전달되도록 보장한다.
			- 일반적으로 특정 데이터 모델을 요구하지 않고 어떤 인코딩도 사용 가능하다.
				- 인코딩이 backward / forward compatible하면 컨슈머 / 프로듀서를 자유롭게 바꿀 수 있다.
		- Distributed actor framework
			- Actor 모델은 단일 프로세스 내에서 동시성을 얻기 위한 프로그래밍 모델이다.
				- 잠재적 문제가 있는 스레드로 병렬 처리하지 않고, 로직을 캡슐화된 독립 프로세스 actor로 감싼다.
			- 분산 actor 프레임워크에서는 프로그래밍 모델이 여러 노드에 걸쳐 스케일될 수 있다.
			- 액터 모델은 단일 프로세스에서도 메시지가 없어질 것이라는 가정을 해서 RPC보다 Location transparency가 잘 작동한다.
			- 분산 액터 프레임워크는 MQ와 액터 프로그레밍 모델은 결합한 구조가 된다.
			- 분산 액터 프레임워크는 다음과 같이 메시지 인코딩을 처리한다.
				- Akka는 자바 기본 시리얼라이저 쓰는데, 프로토콜 버퍼로 대체 가능하다.
				- Orleans는 기본적으로 롤링업데이트 지원 안하는 커스텀 인코딩 쓴다.
				- Erlang OTP는 스키마 변경이 가능은 하지만, 굉장히 어렵다.