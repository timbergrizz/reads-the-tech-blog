- Replication : 동일한 데이터를 네트워크로 연결된 여러 개의 머신에 저장하는 것
	- 다음과 같은 목적을 달성하기 위함
		- 위치상으로 유저에게 가까운 곳에 데이터를 저장 (레이턴시 줄이기)
		- 시스템의 일부에 장애가 발생해도 작동하도록 함 (가용성 증대)
		- 읽기 쿼리가 가능한 머신을 확장 가능하도록 함 (읽기 성능 향상, 확장 가능성)
- Leaders and Followers
	- DB에 발생한 모든 쓰기는 모든 레플리카에서 처리되어야 한다
		- 이를 처리하는 가장 일반적인 솔루션은 Leader-based Replication이다.
- Leader-based Replication
	- Leader-based Replication
		- 레플리카 중 하나를 리더로 설정하고, 클라이언트가 리더로만 쓰기 요청을 보내도록 한다.
			- 리더는 수정이 발생하면 로컬에 저장하고,  복제 로그나 변경 스트림을 팔로워로 보낸다.
		- 다른 레플리카는 팔로워로, 리더로부터 로그를 받아 로컬 데이터를 업데이트한다.
		- 읽기 쿼리는 리더나 팔로워나 상관 없고, 쓰기만 항상 리더 레플리카로 보낸다.
	- Synchronous Versus Asynchronous Replication
		- 레플리케이션 시스템은 동기적으로 이루어질지, 비동기적으로 이루어질지가 중요하다.
		- Synchronous Replication
			- 리더가 팔로워로 데이터가 전송 될 때 까지 쓰기를 완전히 처리하지 않는다.
			- 팔로워가 리더와 일치하는 최신의 데이터를 갖고 있음이 보장된다.
			- 팔로워가 문제등의 이유로 응답을 하지 않은 경우 쓰기가 처리되지 않는다.
				- 이러한 이유로 모든 팔로워를 동기적으로 설정하지 않는다.
		- Asynchronouse Replication
			- 리더가 팔로워로 데이터가 전송되지 않아도 처리한다.
		- 일반적으로 leader-based 구조는 완전하 비동기적으로 구성된다.
			- 리더가 죽고, 일치하지 않는 팔로워가 있으면 recover가 불가능해진다.
			- 대신 리더가 멀쩡하면 팔로워가 죽어도 리더가 쓰기를 처리할 수 있게 한다.
	- Setting Up New Followers
		- 새로운 팔로워를 추가할 때, 리더의 데이터 전송을 어떻게 보장할 것인가?
		- 이론적으로 다음과 같은 이론으로 작동한다.
			- 리더의 스냅샷을 지속적으로 따둔다.
			  logseq.order-list-type:: number
			- 새로운 팔로워 노드로 스냅샷을 카피한다.
			  logseq.order-list-type:: number
			- 팔로워는 리더로 스냅샷 시점부터 지금까지의 데이터 변경을 요청한다.
			  logseq.order-list-type:: number
		- 스냅샷부터의 데이터 변경 백로그를 모두 처리하면 복제된것으로 본다.
	- Handling Node Outages
		- 어떤 노드든 어떤 이유로도 죽기 때문에, 개별 노드가 죽어도 시스템이 작동할 수 하는것을 목표로 한다.
		- Follower failure : Catch-up Recovery
			- 팔로워는 로그 확인하고 처리된 마지막 트랜젝션 이후로 발생한 모든 데이터 변경을 요청하면 된다.
		- Leader failure: Failover
			- 리더가 죽으면 팔로워 중 한명이 리더로 선출되어야 한다.
			- 다음과 같은 프로세스로 진행된다.
				- 리더가 failed 상태인지를 확인한다.
				  logseq.order-list-type:: number
				- 새 리더를 election 과정을 통해 선출한다. 
				  logseq.order-list-type:: number
				- 시스템이 새 리더를 사용하도록 설정한다.
				  logseq.order-list-type:: number
			- 다음과 같이 Failover과정에서 문제가 발생할 수 있다.
				- 비동기로 복제된 경우 새로운 리더가 기존 리더의 fail 이전 모든 데이터를 받지 못했을 수 있다.
				- DB 외의 외부 스토리지 시스템이 DB와 coordinate 돼야 하는 경우 쓰기를 버리는게 위험해진다.
					- Auto-Incrementing PK가 사용되는 경우, 리더로 promote되었을 때 PK가 중복 사용 된 장애가 존재한다.
				- 특정 장애 시나리오에서, 두 노드가 서로 리더라고 여기는 멀티 리더 상태가 되어 모두 쓰기를 받으면서 conflict를 해소하지 않게 되는 경우가 발생한다.
				- 리더의 타임 아웃 시간이 너무 짧으면 필요 없는 failover가 발생하게 된다.
			- 이걸 처리하는 쉽고 마땅한 방법은 없다.
	- Implementation of Replication Logs
		- Statement-based Replication
			- 리더가 모든 쓰기 Statement를 저장하고 실행한 뒤 팔로워에게 전달한다.
			- 다음과 같은 문제가 발생할 수 있다.
				- RAND(), NOW()같은 데이터가 결정되어 있지 않은 함수를 쓸때 레플리카에 다른 데이터가 생성될 수 있다.
				  :LOGBOOK:
				  CLOCK: [2025-02-06 Thu 14:49:21]
				  CLOCK: [2025-02-06 Thu 14:49:27]
				  CLOCK: [2025-02-06 Thu 14:49:31]
				  :END:
				- Auto-Incrementing를 쓰거나 기존 데이터에 의존하는 경우, 레플리카에 Statement들이 정확한 순서로 전달되어야 한다.
				- 사이드 이펙트가 있는 Statement의 경우 레플리카에 따라 결과가 달라질 수 있다.
		- Write-ahead Log (WAL) shipping
			- Log는 DB에서 발생한 쓰기를 모두 포함하는 append-only인 바이트 시퀀스다.
			- 이 로그를 다른 노드에서 레플리카를 빌드하는데 사용할 수 있다.
			- 단점은, 이 로그는 로우레벨에서 표현된다는 점이다.
				- 이 로그는 디스크 블락의 어떤 바이트가 바뀌었는지를 포함하고, 레플리케이션을 스토리지 엔진에 커플링하게 된다.
				- DB의 스토리지 포맷이 변경되면, DB의 다른 버전을 사용할 수 없게 된다.
		- Logical (row-based) log replication
			- 레플리케이션 로그를 스토리지 엔진 내부와 디커플된 로그 포맷을 사용하는 방법이 있다.
				- 스토리지 엔진의 Physical Log와 구분하기 위해 이러한 로그를 Logical Log라고 한다.
			- 관계형 DB의 Logical Log는 행 단위로 DB 테이블에 발생한 쓰기를 설명하는 레코드 시퀀스이다.
				- Insert의 경우 모든 행단위의 새로운 값을 포함한다.
				- Delete의 경우는 삭제된 행을 unique하게 인식할 수 있는 정보를 저장한다.
				- Update의 경우는 수정한 행을 unique하게 인식할 수 있는 정보와 모든 수정된 값을 저장한다.
			- 여러 개의 행을 수정하는 트랜젝션은 수행된 트랜젝션을 수행한 후 이런 로그 레코드를 만든다
			- 로지컬 로그는 스토리지 엔진과 디커플되는 장점이 있다.
				- 하위호환성을 맞추기 좋아져 리더와 팔로워가 다른 DB 버전을 사용할 수 있게 된다.
				- 분석을 위한 데이터 웨어하우스로의 이동같이 외부 어플리케이션이 파싱하기도 좋아진다.
		- Trigger-based replication
			- 다른 Replication은 모두 어플리케이션 레이어가 아닌 DB 레이어에서 이루어진다.
				- 더 많은 유연성이 필요한 상황들이 존재하고, 이러한 경우 앱 레이어에서 복제를 수행할 수 있다.
			- 어플리케이션 코드를 트리거에 등록하면, 데이터 변경이 발생할 때 자동으로 실행하도록 한다.
			- 다른 레플리케이션에 비해 오버헤드가 크고, 버그에 취약하며 한계가 있다.
				- 확장성이 필요한 경우는 쓰기 좋다.
	- Problems with Replication Lag
		- 레플리케이션은 노드 장애 tolerance뿐만 아니라 레이턴시나 확장성에서도 이점이 있다.
		- Leader-based Replication은 모든 쓰기가 리더 노드로 가고, 읽기는 어떤 노드로도 갈 수 있다.
			- 읽기 위주의 쓰기가 적게 발생하는 아키텍처에서는 이런전략이 문제가 없다.
			- 이런 접근은 Asynchronous replication에서만 현실적으로 작동한다.
				- Synchronous인 경우 단일 노드 장애가 전체 시스템 장애로 이어질 수 있다.
				- Asynchronous인 경우는 또 팔로워가 out-dated된 데이터를 제공할 수도 있고, 이는 DB의 inconsistency로 이어질 수 있다.
					- 일시적인 상태고, 리더가 쓰기를 중단하면 팔로워는 언젠가 리더와 consistent해진다.
						- eventual consistency라고 한다.
						- 이것도 말이 애매한게 결과적으로 맞춰지긴 한데 언제가 될진 모른다.
							- lag 커지면 실제 어플리케이션으로의 문제가 된다.
		- Reading Your Own Writes
			- 문제 : 비동기 복제의 경우, 쓰기 직후 읽기를 수행하면 새로운 데이터가 레플리카에 전달되지 않았을 수 있다.
			- read-after-write consistency가 필요하다.
				- 유저가 새로고침을 하면 항상 제출한 업데이트를 확인할 수 있어야 한다.
			- leader-based replication에서 다음과 같이 구현할 수 있다.
				- 유저가 수정했을 수 있는 데이터를 읽을 때, 리더에서 읽도록 한다.
				- 유저가 대부분의 데이터를 수정 가능할 땐, 다른 전략으로 리더에서 읽을지 여부를 결정한다.
				- 클라이언트는 최근 쓰기의 타임스탬프를 대부분 기억할 수 있고, 따라서 시스템은 레플리카가 업데이트를 반영했는지 판단하도록 할 수 있다.
				- 레플리카가 여러 데이터센터에 구성된 경우, 추가적인 복잡성이 더해진다.
			- 동일한 유저가 복수의 디바이스를 이용해 서비스에 접근할 때 추가적인 복잡성이 발생하고, 다음과 같은 이슈를 추가적으로 고민해야 한다.
				- 타임스탬프를 기억하여 요청하는 접근이 다른 디바이스에서 접근하게 되므로 어려워진다.
				- 레플리카가 여러 데이터센터에 구성된 경우, 다른 디바이스가 같은 데이터센터로 요청할 것이라는 보장이 없다.
			- Monotonic Reads
				- 문제: 비동기 팔로워에서에서 읽기를 수행할 때 데이터가 과거로 가는 것 처럼 보이는 경우가 발생할 수 있다.
				- Monotonic Reads는 이런 이상이 발생하지 않도록 보장한다.
					- strong consistency보다 약하고, eventual consistency보다 강한 보장이다.
				- 유저가 한 시점에서 데이터를 봤으면, 그것보다 빠른시점의 데이터는 보면 안된다.
			- Consistent Prefix Reads
				- 문제: 관찰자의 입장에서 서로 다른 노드의 입력 순서가 달라지는 것 처럼 보일 수 있다.
				- 이러한 문제를 막기 위해 consistent prefix read 보장이 필요하다.
					- 쓰기가 특정 순서로 발생했으면, 읽는 모든 사람이 쓰기의 순서대로 볼 수 있어야 한다.
				- 샤딩에서 주로 문제가 된다.
					- 많은 분산DB에서 파티션들이 독립적으로 작동해서, 쓰기에 대한 global ordering이 없다.
		- Solutions for Replication Lag
			- 시스템이 강한 보장을 제공할 수 있도록 디자인하는 것이 중요하다.
				- 비동기 복제를 동기처럼 보이도록 하는 것이 문제를 해결하는 방법이다.
			- 어플리케이션이 DB에 아래 있는 DB에 대해 강한 보장을 줄 수 있는 방법이 있다.
				- 이러한 이슈를 어플리케이션 레이어에서 다루는건 복잡하고 잘못되기 쉽다.
				- 어플리케이션 개발자들이 걱정할 필요 없이 DB를 신뢰 할 수 있는게 최선이고, 그래서 트랜젝션이라는게 존재한다.
					- 성능과 가용성에서 너무 큰 비용이라 트랜젝션을 버린 시스템도 많다.
- Multi-Leader Replication
	- 리더가 하나인 경우, 모든 쓰기가 하나의 리더 노드를 거쳐 가야 한다.
		- 리더 연결 안되면 DB로의 쓰기 자체가 불가능해진다.
	- 하나 이상의 노드가 쓰기를 받도록 리더를 확장하는 것이 Multi-Leader Replication이다.
		- 복제는 동일하게 리더들이 팔로워로 데이터 변경을 전송하도록 한다.
	- Use Case for Multi-Leader Replication
		- Multi-datacenter operation
			- 복수의 데이터 센터를 사용하는 시스템에서 단일 노드 리더인 경우 모든 쓰기가 하나의 데이터센터로 가야한다.
			- 분산 시스템의 데이터 센터마다 리더를 만들고, 각 데이터센터들의 리더들끼리 복제를 하도록 한다.
			- 다음과 같은 향상이 있다.
				- 성능
					- 싱글 리더에서 모든 쓰기가 리더가 있는 데이터 센터로 가야 하고, 추가적인 오버헤드가 발생한다.
					- 멀티 리더에선 쓰기가 로컬 데이터센터에서 처리되고, 비동기적으로 다른 데이터센터로 복제되어 레이턴시가 크게 감소한다.
				- 데이터센터 장애에 대한 저항성
					- 싱글 리더는 리더가 존재하는 데이터센터가 죽으면 Failover가 수행되어 팔로워 하나를 Promote 해야 한다.
					- 멀티 리더에선 각 데이터 센터가 다른 데이터센터와 관계 없이 작동할 수 있고, 장애가 발생한 데이터센터가 돌아오면 catch up 하도록 한다.
				- 네트워크 장애에 대한 저항성
					- 데이터 센터 간의 트래픽은 데이터센터 로컬 네트워크보다 불안정한 퍼블릭 인터넷을 탄다.
					- 싱글 리더는 복제가 데이터센터 커넥션으로 이루어져, 네트워크 문제가 크게 작용한다.
					- 멀티 리더는 이러한 문제에 대해 저항성이 높고, 네트워크 장애가 생겨도 쓰기가 가능하다.
			- 멀티 리더는 같은 데이터가 다른 데이터센터에서 동시에 수정된 경우, 컨플릭트가 발생한다.
			- 많은 DB에서 개조형태로 멀티 리더를 지원하기 때문에, DB 기본 기능과 같이 사용하는 경우 장애가 발생할 수 있다.
		- Client with offline operation
			- 인터넷에 연결되지 않아도 어플리케이션이 작동해야하는 경우 멀티 리더가 적절하다.
				- 오프라인에서 발생한 변경도 서버로 싱크되어 다른 디바이스에서 확인할 수 있어야 한다.
				- 이러한 경우, leader처럼 동작하는 로컬 데이터베이스를 모든 디바이스가 사용한다.
					- asynchronous multi-leader replication을 디바이스 간에 수행한다.
			- 아키텍처적 관점에서 위같은 상황은 데이터센터간의 멀티 리더 복제로 볼 수 있다.
		- Collaborative editing
			- 협업 수정은 여러 유저가 문서를 동시에 수정할 수 있도록 한다.
				- 수정이 발생하면 즉시 로컬 레플리카에 저장이 되고, 같은 문서를 수정하는 다른 유저들과 비동기적으로 복제가 되어야 한다.
				- 컨플릭트를 피하려면 문서에서 락을 걸어야 하고, 이는 싱글리더 복제와 유사하다.
				- 동시 수정을 구현하기 위해선 위해서는 락을 피하고 수정 단위를 최소화해야 한다.
					- 이는 컨플릭트 해결을 포함한 멀티 리더 복제의 모든 과제를 해결해야 한다.
	- Handling Write Conflict
		- 멀티 리더 복제의 가장 큰 문제는 컨플릭트가 발생할 수 있다는 것이다.
			- 유저 두명이 동일한 데이터를 다른 리더로 동시에 수정하면, 로컬 리더에 반영은 되는데 리더끼리 컨플릭트가 발생한다.
		- Synchronous versus asynchronous conflict detection
			- 싱글 리더에선 먼저 들어온 쓰기를 먼저 수행하고, 뒤에 들어온건 나중에 처리하거나 버린다.
			- 멀티 리더에서는 두 쓰기가 모두 성공하고, 싱크 과정에서 컨플릭트가 발견된다.
				- 컨플릭트 탐지를 동기적으로 수행할 수도 있는데, 이러면 각 레플리카가 독립적으로 쓰기를 받는건 포기해야 한다.
		- Conflict avoidance
			- 가장 간단한 전략은 걍 피하는거다.
				- 특정 레코드에 대한 쓰기를 같은 리더로만 보내면 컨플릭트는 발생하지 않는다.
			- 서로 다른 유저는 각각 가장 가까운 데이터센터를 가지고, 유저 관점에선 싱글리더로 만들 수 있다.
			- 레코드에 대해 설정된 리더를 바꾸려 할 때 이 전략이 불가능할 수 있다.
		- Converging toward a consistent state
			- 싱글 리더는 쓰기를 순차로 처리하여, 같은 필드에 업데이트 발생하면 마지막 값만 남는다.
			- 멀티 리더는 쓰기에 설정된 순서가 없어서 무슨 값이 최종값인지 결정하기 어렵다.
				- 각 레플리카가 쓰기 순서대로 처리하게 된다면, 레플리카끼리 inconsistent해진다.
				- 따라서 레플리카들이 동일한 최종 결과로 수렴하도록 컨플릭트를 해결해야 한다.
			- 다음과 같은 방법으로 최종 값을 수렴하도록 할 수 있다.
				- 모든 쓰기에 유니크한 ID를 부여하고, 가장 큰 ID를 갖는 쓰기로 결정한다.
				- 각 레플리카에 유니크한 ID를 부여하고, 레플리카간의 우선 순위를 결정하여 처리한다.
				- 어떻게든 데이터를 머지한다.
				- 발생한 컨플릭트의 정보를 외부에 저장하고, 어플리케이션 코드로 컨플릭트를 해결한다.
			- Custom conflict resolution logic
				- 대부분의 멀티리더 복제 툴은 어플리케이션 코드로 컨플릭트를 해결할 수 있도록 한다.
				- 쓰기 혹은 읽기 시점에서 실행된다.
					- 쓰기 : DB 시스템이 컨플릭트를 감지하면, 컨플릭트 핸들러를 호출하여 해결한다.
					- 읽기 : 컨플릭트가 감지되면 모든 컨플릭트가 발생한 쓰기를 저장하고, 다음 데이터를 읽을 때 어플리케이션에서 여러 버전을 리턴한다.
				- Automatic Conflict Resolution
					- 동시 데이터 수정에서 자동으로 컨플릭트를 해결하는 방법이 연구되고 있다.
					- Conflict-free replicate datatypes
						- Map, Set같은 자료구조고, 여러 유저의 동시 입력을 지원하고 컨플릭트를 자동으로 해결하는 방법을 제공한다.
					- Mergeable persistent data structures
						- 깃처럼 명시적으로 히스토리를 추적하고, 3-way 머지 함수를 사용한다.
					- Operational transformation
						- 협업 어플리케이션에서 컨플릭트 해결을 위해 사용되는 알고리즘이다.
		- What is a conflict?
			- 컨플릭트 어떤건 좀 애매하다.
				- 동일한 레코드의 동일한 필드에서 동시에 발생한 두개의 다른 값으로 하는 수정은 의심할 여지가 거의 없다.
				- 이거 말고도 다른 타입의 컨플릭트가 발생할 수 있다.
					- 예약 시스템에서 동일한 슬롯에 대해 복수의 요청이 발생하는 것은 컨플릭트이다.
	- Multi-Leader Replication Topologies
		- Replication topology는 쓰기가 노드간에 전파되는 경로이다.
			- 리더가 2개면 한가지 전파 경로밖에 없지만, 2개 이상인 경우 여러 전략이 가능하다.
		- 가장 일반적인 전략은 all-to-all이다.
			- 모든 리더는 모든 다른 리더로 쓰기를 전송한다.
			- 모든 리더로 가는 속도가 같지 않기 때문에, 의존성이 있는 로그도 순서가 바뀔 수 있다.
				- 순서를 적절하게 배치하기 위해서 version vector같은것도 사용할 수 있다.
				- 근데 보통은 컨플릭트 감지가 구현이 개판이라, 확인 직접 해보는게 좋다.
		- 다른 제한된 topology도 사용된다.
			- MySQL은 기본적으로 circular topology 사용한다.
			- star topology처럼 하나의 노드가 다른 노드들로 전파하는 구조도 사용된다.
			- circular, start topology에서, 쓰기가 모든 레플리카로 도달하기 위해 통과하는 노드가 길다.
				- 루프를 방지하기 위해서, 각 노드가 유니크한 인식자를 필요로 하며, 복제 로그에 지나온 로그를 기록해야 한다.
			- 이 경우, 노드 하나에서 장애가 발생했을 때 다른 노드들이 다 망가지는 경우가 발생할 수 있다.
- Leaderless Replication
	- 리더 - 팔로워 컨셉 자체를 버리고 항상 클라이언트로부터 쓰기를 받도록 하는 방법도 있다.
		- 이러한 방식을 leaderless라고 한다.
	- 리더리스 구조에선 클라이언트가 여러개의 레플리카로 쓰기 요청을 보내고, 안보낸 노드는 코디네이터가 보낸다.
		- 코디네이터가 쓰기 순서를 보장하지 않는다.
	- Writing to the Database When a Node Is Down
		- 리더리스 구조에선 failover가 존재하지 않는다.
			- 가용불가한 레플리카는 그냥 쓰기 자체를 놓친다.
			- 이때 outdated된 결과가 돌아올 수 있다.
				- 클라이언트는 여러 개의 레플리카로 동시에 요청을 보내고, 가장 최신의 데이터를 사용한다.
				- outdated된 결과를 반환한 노드로 업데이트도 수행한다.
		- Reader repair and anti-entropy
			- Read repair
				- 클라이언트가 동시에 여러개의 레플리카로 읽기를 보내면 outdated된 결과를 찾을 수 있다.
				- 이 경우 클라이언트가 레플리카로 최신 버전에 데이터를 보내 수정하도록 한다.
			- Anti-entropy process
				- 레플리카간의 데이터 차이를 확인하는 백그라운드 프로세스를 운영하는 경우도 존재한다.
				- Anti-entropy의 경우 특정 순서로 쓰기로그를 카피하지 않고, 과정에 큰 딜레이가 있을 수 있다.
		- Quorums for reading and writing
			- 쓰기, 읽기의 성공을 보장하기 위해서 다음과 같은 식으로 노드 수를 결정한다.
			- n = 레플리카의 수, w = 쓰기에 성공한 노드의 수, r = 읽기 요청을 보낸 노드의 수
				- w + r > n을 만족할 때 읽기 과정에서 최신의 값을 읽는다고 보장할 수 있다.
				- 일반적으로 n을 3, 5 등 홀수로 설정하고, w = r = (n + 1) / 2로 설정한다.
			- quorum condition은 다음과 같이 사용 불가한 노드에 대한 저항성을 갖는다.
				- w < n인 경우 노드가 사용 불가여도 쓰기를 수행할 수 있다.
				- r < n인 경우 노드가 사용 불가해도 읽기를 수행할 수 있다.
				- n = 3, w = 2, r = 2인 경우 하나의 노드까지 장애를 감당할 수 있다.
				- n = 5, w = 3, r = 3인 경우 2개의 노드까지 장애를 감당할 수 있다.
				- 일반적으로 모든 레플리카로 읽기 쓰기 요청 보내고, 몇개 기다릴건지의 파라미터가 w, r
			- Limitations of Quorum Consistency
				- 일반적으로 r, w는 노드의 과반수로 선택되지만, quorom이 필수 조건은 아니다.
					- w, r을 더 작게 설정할 수 있고, 이 경우 더 적은 성공 응답이 와도 요청이 성공했다 간주한다.
					- 더 작게 설정된 경우 outdated된 데이터를 읽을 가능성이 높아지지만, 레이턴시가 짧아지고 가용성이 높아진다.
				- w + r > n을 만족하는 경우에도 outdated된 결과가 반환되는 경우가 발생할 수 있다.
					- sloppy quorum을 사용하는 경우, w가 r이 읽은 노드에 포함되지 않는 노드에 쓰기가 이루어질 수 있다.
					- 두 개의 쓰기가 동시에 발생한 경우, 어떤게 먼저 발생했는지 판단하기 어렵고 timestamp 기반으로 merge했을 때 데이터가 손실될 수 있다.
					- 쓰기가 읽기와 동시에 발생했을 때, 일부 레플리카에만 쓰기가 반영되었을 수 있다.
					- w개를 넘지 않는 일부 레플리카에서만 쓰기가 성공했을 경우, 성공한 레플리카가 롤백을 수행하지 않고 쓰기가 실패했다고 해도 어떤 데이터가 반환될지 모른다.
					- 새로운 값을 가진 노드가 장애가 발생하고, 오래된 값만 가진 레플리카에서 복구될 때 새로운 데이터가 유실되어 quorum을 깰 수 있다.
					- 모든게 잘 작동해도 어떤 장애가 생길지 모른다.
				- w, r을 잘 조정하는것도 중요한데, 이게 보장이 아니라는걸 이해해야 한다.
			- Monitoring staleness
				- 운영 관점에서, 최신 데이터를 반환하고 있는지 확인하는게 중요하다.
				- 리더 기반 복제에서 DB는 replication lag을 모니터링에서 확인한다.
					- 리더 -> 팔로워라는 데이터 흐름의 순서가 있어서 가능하다.
				- 리더리스 복제에선 쓰기가 적용되는 순서가 없어 모니터링이 어렵다.
				- n, w, r 파라미터로 측정하는 연구가 있긴 하나, 아직은 완전하지 않다.
			- Sloppy Quorums and Hinted Handoff
				- 적절하게 설정된 Quorum은 개별 노드의 높은 레이턴시나 실패를 수용할 수 있다.
				- 하지만 설명된만큼 실패에 대해 강력하지 않다.
					- 네트워크 장애로 대규모의 DB가 접근 불가하면 죽은걸로 처리된다.
				- 대규모 클러스터에서 클라이언트는 네트워크 장애 도중 DB 노드에 연결할 수 있다.
					- 이 경우 다음과 같은 선택을 해야한다.
						- w, r quorum만큼 성공하지 못했으니 에러를 반환해야 하는가?
						- 일부 노드에라도 쓰기를 허용해야 하는가?
					- 후자를 sloppy quorum이라고 한다.
				- 쓰기와 읽기는 여전히 w, r개의 요청을 필요로 하나, n에 포함되지 않은 노드가 있을 수 있다.
					- n에 포함되지 않는 근처에 있는 노드에 저장하게 된다.
				- Sloppy Quorum은 쓰기의 가용성을 향상시키는데 유용하다
					- w개의 노드가 가용하면 DB는 쓰기를 처리할 수 있다.
					- 대신 w + r > n을 만족하더라도 다른 노드에 저장됐을 수 있어 최신값을 보장할 수 없게 된다.
				- Sloppy Quorum은 트레디셔널한 관점에서 quorum은 아니다.
					- 내구성에 대한 일종의 보장이며, 어딘가에 있는 w개의 노드에 저장될거라는 뜻이다.
					- r개의 노드 안에 저장되어 있을거라는 보장은 없다.
			- Multi-datacenter operation
				- 리더리스 복제는 다중 데이터센터 운영에 적절하다.
					- 레이턴시 스파이크, 네트워크 장애, 동시 쓰기 컨플릭트를 tolerate하도록 설계했기 떄문
				- 카산드라, 볼드모트는 기본적으로 구현을 제공한다.
					- n은 모든 데이터센터의 노드를 포함하고, 설정에서 각 데이터 센터에 n개의 레플리카를 몇개씩 배치할건지 설정할 수 있다.
		- Detecting Concurrent Writes
			- The happens-before relationship and concurrency
				- 두 동작이 동시에 발생했다는 것을 어떻게 결정할 것인가?
					- A 동작이 반영되어 B가 확인하고 발생했으면 causally dependent하다고 할 수 있다.
					- 그걸 확인하지 못하고 수행되면 동작 간의 causal dependency가 없다고 한다.
					- B가 A에 대해 알고 있을 때만 A와 B의 순서를 결정할 수 있다.
					- A, B 두개의 operation이 있을 때 3가지 케이스가 있다.
						- A -> B, B -> A, Concurrent
					- 두 오퍼레이션이 동시에 발생했는지 판단하는 알고리즘을 필요로 한다.
						- 완전히 동시에 발생했는지 판단이 어렵기 때문에 시간의 중복은 중요하지 않다.
						- 두 오퍼레이션이 서로를 인지하지 못하고 발생했을 때 concurrent하다고 한다.
				- Capturing the happens-before relationship
					- 서버에서 데이터에 버전을 설정하고, 이를 비교하여 동시성을 판단하도록 할 수 있다.
						- 이렇게 하여 operation 간의 순서를 결정할 수 있다.
					- 서버는 버전 넘버 확인을 통해 두 동작의 동시성을 확인할 수 있다.
					- 알고리즘은 다음과 같이 작동한다
						- 모든 키에 대해 버전 넘버를 설정하고, 쓰기가 발생할 때 마다 증가시킨다.
						- 클라이언트가 키를 읽으면 서버는 덮어쓰기되지 않은 모든 값을 반환한다.
						- 클라이언트가 쓰기를 수행하면, 이전 읽기에서 사용한 버전을 포함해야 하며, 이전 읽기에서 포함된 모든 값을 머지해야 한다.
						- 서버가 버전 넘버가 설정된 값을 받으면, 버전넘버보다 낮은 값을 모두 수정한다.
							- 더 높은 버전넘버가 설정된 값은 유지한다.
					- 버전 넘버 없이 쓰기를 수행하면, 모든 쓰기와 동시에 발생하게 되어 아무것도 쓰기가 발생하지 않는다.
						- 읽기가 반환하는 여러 개의 값 중 하나가 된 것이다.
			- 다이나모 스타일 db는 여러 클라이언트가 동일한 키로 쓰기를 할 수 있도록 허용한다.
				- 당연히 conflict가 발생할 수 있다.
			- 문제는 이벤트가 네트워크 지연이나 장애로 서로 다른 노드에 다른 순서로 도착해서 발생한다.
				- 순서대로 쓰기를 처리하면 노드가 inconsistent해진다.
				- eventually consistent를 만족하려면 레플리카가 동일한 값으로 결론을 내야한다.
			- 다음과 같은 전략으로 쓰기 컨플릭트를 해결한다
				- Last write wins (discarding concurrent writes)
					- 가장 최신의 값만 저장하고, 오래된 값은 걍 덮어쓰고 버려지도록 하는 것이다.
					- 동시에 작성이 되었다면 프로세스 상에선 이게 어떤 순서로 작성되었는지 결정할 수 없다.
						- 모든 쓰기에 타임스탬프를 기록하고, 가장 최신의 타임스탬프만을 골라 해결할 수 있다.
					- 결과적 컨버전스는 달성하지만, 실패한 수정들을 버리기 때문에 durability가 떨어진다.
						- 쓰기가 손실되면 안되는 경우 사용하면 안된다.
					- 안전하게 쓰려면 같은 키에 동시 수정이 발생하지 않도록 하는 것이다.
			- Merging concurrently written values
				- 여러개의 동작이 동시에 발생하면, 클라이언트가 이를 머지해서 정리해야한다.
					- 가장 간단한 방법은 버전 넘버나 타임스탬프로 하나 찍는건데, 이건 데이터 손실된다.
				- 없어지는 데이터는 없지만 클라가 추가적인 작업을 수행해야 한다.
				- 데이터가 추가만 되면 좋겠지만, 삭제가 발생하는 경우도 있어 해결하는 방법을 정의해야 한다.
			- Version Vectors
				- 여러 개의 레플리카가 존재할 때, 레플리카마다 버전 넘버를 사용해야 한다.
				- 모든 레플리카에서의 버전 넘버의 집합을 버전 벡터라 한다.
				- 버전 벡터는 데이터를 머지할 때 다른 레플리카로 작성하는 걸 안전하게 하도록 한다.
					- 추가적인 sibling 데이터가 발생은 하나, 모든 데이터가 적절하게 머지된다.